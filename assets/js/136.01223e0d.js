(window.webpackJsonp=window.webpackJsonp||[]).push([[136],{808:function(e,a,s){"use strict";s.r(a);var n=s(4),t=Object(n.a)({},(function(){var e=this,a=e.$createElement,s=e._self._c||a;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("p",[e._v("作者：薛明")]),e._v(" "),s("p",[e._v("编者：范志东")]),e._v(" "),s("p",[e._v("两个月前，微软发布了GraphRAG的论文"),s("a",{attrs:{href:"https://arxiv.org/abs/2404.16130",target:"_blank",rel:"noopener noreferrer"}},[e._v("《From Local to Global: A Graph RAG Approach to Query-Focused Summarization》"),s("OutboundLink")],1),e._v("，基于知识图谱技术改进查询聚焦摘要（QFS）任务的问答，我也在之前的文章"),s("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/703735293",target:"_blank",rel:"noopener noreferrer"}},[e._v("《Vector | Graph：蚂蚁首个开源Graph RAG框架设计解读》"),s("OutboundLink")],1),e._v("中提到借鉴“图社区总结”的思路对框架进行改进。7月2日，微软正式官宣"),s("a",{attrs:{href:"https://github.com/microsoft/graphrag",target:"_blank",rel:"noopener noreferrer"}},[e._v("GraphRAG项目"),s("OutboundLink")],1),e._v("开源，短短一周破8K星。相信不少小伙伴已经开始着手分析项目的代码和文档了，这里奉上外网薛同学新鲜出炉的源码解读文章，以飨读者。")]),e._v(" "),s("blockquote",[s("p",[e._v("本文经作者全权授权转载。\n原文链接："),s("a",{attrs:{href:"https://m1n9x.vercel.app/2024/07/09/%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%20-%20%E5%BE%AE%E8%BD%AFGraphRAG%E6%A1%86%E6%9E%B6/",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://m1n9x.vercel.app/2024/07/09/源码解读%20-%20微软GraphRAG框架/"),s("OutboundLink")],1)])]),e._v(" "),s("h3",{attrs:{id:"_1-引言"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_1-引言"}},[e._v("#")]),e._v(" 1. 引言")]),e._v(" "),s("p",[e._v("这几天微软开源了一个新的基于知识图谱构建的检索增强生成（RAG）系统：GraphRAG。该框架旨在利用大型语言模型（LLMs）从非结构化文本中提取结构化数据，构建具有标签的知识图谱，以支持数据集问题生成、摘要问答等多种应用场景。GraphRAG的一大特色是利用图机器学习算法针对数据集进行语义聚合和层次化分析，因而可以回答一些相对高层级的抽象或总结性问题，这一点恰好是常规RAG系统的短板。 说实话之前一直有在关注这个框架，所以这两天花了点时间研究了一下源码，结合之前的一些技术文档，本文主要是记录GraphRAG源码方面的一些解读，也希望借此进一步理解其系统架构、关键概念以及核心工作流等。")]),e._v(" "),s("p",[e._v("本次拉取的GraphRAG项目源码对应commit ID为 "),s("code",[e._v("a22003c302bf4ffeefec76a09533acaf114ae7bb")]),e._v(" ，更新日期为2024.07.05。")]),e._v(" "),s("h3",{attrs:{id:"_2-框架概述"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-框架概述"}},[e._v("#")]),e._v(" 2. 框架概述")]),e._v(" "),s("h3",{attrs:{id:"_2-1-解决了什么问题（what-why）"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-解决了什么问题（what-why）"}},[e._v("#")]),e._v(" 2.1 解决了什么问题（What & Why）?")]),e._v(" "),s("p",[e._v("讨论代码前，我们先简单了解下GraphRAG项目的目标与定位. 在论文中，作者很明确地提出了一个常规RAG无法处理的应用场景：")]),e._v(" "),s("blockquote",[s("p",[e._v("However，RAG fails on global questions directed at an entire text corpus，such as “What are the main themes in the dataset?”，since this is inherently a queryfocused summarization (QFS) task，rather than an explicit retrieval task.")])]),e._v(" "),s("p",[e._v("也就是类似该数据集的主题是什么这种high level的总结性问题，作者认为，这种应用场景本质上一种聚焦于查询的总结性(QueryFocused Summarization，QFS)任务，单纯只做数据检索是无法解决的. 相应的，其解决思路也在论文中清楚地描述出来了：")]),e._v(" "),s("blockquote",[s("p",[e._v("In contrast with related work that exploits the structured retrieval and traversal affordances of graph indexes (subsection 4.2)，we focus on a previously unexplored quality of graphs in this context: their inherent modularity (Newman，2006) and the ability of community detection algorithms to partition graphs into modular communities of closely-related nodes (e.g.，Louvain，Blondel et al.，2008; Leiden，Traag et al.，2019). LLM-generated summaries of these community descriptions provide complete coverage of the underlying graph index and the input documents it represents. Query-focused summarization of an entire corpus is then made possible using a map-reduce approach: first using each community summary to answer the query independently and in parallel，then summarizing all relevant partial answers into a final global answer.")])]),e._v(" "),s("p",[e._v("利用社区检测算法（如Leiden算法）将整个知识图谱划分模块化的社区(包含相关性较高的节点)，然后大模型自下而上对社区进行摘要，最终再采取map-reduce方式实现QFS: 每个社区先并行执行Query，最终汇总成全局性的完整答案.")]),e._v(" "),s("h3",{attrs:{id:"_2-2-实现方式是什么（how）"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-实现方式是什么（how）"}},[e._v("#")]),e._v(" 2.2 实现方式是什么（How）?")]),e._v(" "),s("blockquote"),e._v(" "),s("p",[s("img",{attrs:{src:"zhimg.com/v2-5bdaa087a521b3a4b03b65625111c60d_r.jpg",alt:""}})]),e._v(" "),s("blockquote"),e._v(" "),s("p",[e._v("论文中给出了解决问题的基本思路，与其他RAG系统类似，GraphRAG整个Pipeline也可划分为索引(Indexing)与查询(Query)两个阶段。索引过程利用LLM提取出节点（如实体）、边（如关系）和协变量（如 claim），然后利用社区检测技术对整个知识图谱进行划分，再利用LLM进一步总结。最终针对特定的查询，可以汇总所有与之相关的社区摘要生成一个全局性的答案。")]),e._v(" "),s("h3",{attrs:{id:"_3-源码解析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-源码解析"}},[e._v("#")]),e._v(" 3. 源码解析")]),e._v(" "),s("p",[e._v("官方文档说实话写得已经很清楚了，不过想要理解一些实现上的细节，还得深入到源码当中. 接下来，一块看下代码的具体实现. 项目源码结构树如下：")]),e._v(" "),s("div",{staticClass:"language-language-text line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("├── cache\n├── config\n├── emit\n├── graph\n│ ├── embedding\n│ ├── extractors\n│ │ ├── claims\n│ │ ├── community_reports\n│ │ ├── graph\n│ │ └── summarize\n│ ├── utils\n│ └── visualization\n├── input\n├── llm\n├── progress\n├── reporting\n├── storage\n├── text_splitting\n├── utils\n├── verbs\n│ ├── covariates\n│ │ └── extract_covariates\n│ │ └── strategies\n│ │ └── graph_intelligence\n│ ├── entities\n│ │ ├── extraction\n│ │ │ └── strategies\n│ │ │ └── graph_intelligence\n│ │ └── summarize\n│ │ └── strategies\n│ │ └── graph_intelligence\n│ ├── graph\n│ │ ├── clustering\n│ │ │ └── strategies\n│ │ ├── embed\n│ │ │ └── strategies\n│ │ ├── layout\n│ │ │ └── methods\n│ │ ├── merge\n│ │ └── report\n│ │ └── strategies\n│ │ └── graph_intelligence\n│ ├── overrides\n│ └── text\n│ ├── chunk\n│ │ └── strategies\n│ ├── embed\n│ │ └── strategies\n│ ├── replace\n│ └── translate\n│ └── strategies\n└── workflows\n └── v1\n")])]),e._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[e._v("1")]),s("br"),s("span",{staticClass:"line-number"},[e._v("2")]),s("br"),s("span",{staticClass:"line-number"},[e._v("3")]),s("br"),s("span",{staticClass:"line-number"},[e._v("4")]),s("br"),s("span",{staticClass:"line-number"},[e._v("5")]),s("br"),s("span",{staticClass:"line-number"},[e._v("6")]),s("br"),s("span",{staticClass:"line-number"},[e._v("7")]),s("br"),s("span",{staticClass:"line-number"},[e._v("8")]),s("br"),s("span",{staticClass:"line-number"},[e._v("9")]),s("br"),s("span",{staticClass:"line-number"},[e._v("10")]),s("br"),s("span",{staticClass:"line-number"},[e._v("11")]),s("br"),s("span",{staticClass:"line-number"},[e._v("12")]),s("br"),s("span",{staticClass:"line-number"},[e._v("13")]),s("br"),s("span",{staticClass:"line-number"},[e._v("14")]),s("br"),s("span",{staticClass:"line-number"},[e._v("15")]),s("br"),s("span",{staticClass:"line-number"},[e._v("16")]),s("br"),s("span",{staticClass:"line-number"},[e._v("17")]),s("br"),s("span",{staticClass:"line-number"},[e._v("18")]),s("br"),s("span",{staticClass:"line-number"},[e._v("19")]),s("br"),s("span",{staticClass:"line-number"},[e._v("20")]),s("br"),s("span",{staticClass:"line-number"},[e._v("21")]),s("br"),s("span",{staticClass:"line-number"},[e._v("22")]),s("br"),s("span",{staticClass:"line-number"},[e._v("23")]),s("br"),s("span",{staticClass:"line-number"},[e._v("24")]),s("br"),s("span",{staticClass:"line-number"},[e._v("25")]),s("br"),s("span",{staticClass:"line-number"},[e._v("26")]),s("br"),s("span",{staticClass:"line-number"},[e._v("27")]),s("br"),s("span",{staticClass:"line-number"},[e._v("28")]),s("br"),s("span",{staticClass:"line-number"},[e._v("29")]),s("br"),s("span",{staticClass:"line-number"},[e._v("30")]),s("br"),s("span",{staticClass:"line-number"},[e._v("31")]),s("br"),s("span",{staticClass:"line-number"},[e._v("32")]),s("br"),s("span",{staticClass:"line-number"},[e._v("33")]),s("br"),s("span",{staticClass:"line-number"},[e._v("34")]),s("br"),s("span",{staticClass:"line-number"},[e._v("35")]),s("br"),s("span",{staticClass:"line-number"},[e._v("36")]),s("br"),s("span",{staticClass:"line-number"},[e._v("37")]),s("br"),s("span",{staticClass:"line-number"},[e._v("38")]),s("br"),s("span",{staticClass:"line-number"},[e._v("39")]),s("br"),s("span",{staticClass:"line-number"},[e._v("40")]),s("br"),s("span",{staticClass:"line-number"},[e._v("41")]),s("br"),s("span",{staticClass:"line-number"},[e._v("42")]),s("br"),s("span",{staticClass:"line-number"},[e._v("43")]),s("br"),s("span",{staticClass:"line-number"},[e._v("44")]),s("br"),s("span",{staticClass:"line-number"},[e._v("45")]),s("br"),s("span",{staticClass:"line-number"},[e._v("46")]),s("br"),s("span",{staticClass:"line-number"},[e._v("47")]),s("br"),s("span",{staticClass:"line-number"},[e._v("48")]),s("br"),s("span",{staticClass:"line-number"},[e._v("49")]),s("br"),s("span",{staticClass:"line-number"},[e._v("50")]),s("br"),s("span",{staticClass:"line-number"},[e._v("51")]),s("br"),s("span",{staticClass:"line-number"},[e._v("52")]),s("br"),s("span",{staticClass:"line-number"},[e._v("53")]),s("br")])]),s("h3",{attrs:{id:"_3-1-demo"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-1-demo"}},[e._v("#")]),e._v(" 3.1 Demo")]),e._v(" "),s("p",[e._v("研究具体功能前，先简单跑下官方demo，上手也很简单，直接参考"),s("a",{attrs:{href:"https://microsoft.github.io/graphrag/posts/get_started/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Get Started (microsoft.github.io)"),s("OutboundLink")],1),e._v(" 即可。 高能预警: 虽然只是一个简单demo，但是Token消耗可是一点都不含糊，尽管早有预期，并且提前删除了原始文档超过一半的内容，不过我这边完整跑下来还是花了差不多3刀费用，官方完整demo文档跑一遍，预计得消耗5~10刀。")]),e._v(" "),s("p",[e._v("这里实际运行时间还是比较慢的，大模型实际上是来来回回的在过整个文档，其中一些比较重要的事项如下：")]),e._v(" "),s("ul",[s("li",[e._v("目录结构")])]),e._v(" "),s("div",{staticClass:"language-language-text line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("├── cache\n│ ├── community_reporting\n│ │ ├── create_community_report-chat-v2-0d811a75c6decaf2b0dd7b9edff02389\n│ │ ├── create_community_report-chat-v2-1205bcb6546a4379cf7ee841498e5bd4\n│ │ ├── create_community_report-chat-v2-1445bd6d097492f734b06a09e579e639\n│ │ ├── ...\n│ ├── entity_extraction\n│ │ ├── chat-010c37f5f6dedff6bd4f1f550867e4ee\n│ │ ├── chat-017a1f05c2a23f74212fd9caa4fb7936\n│ │ ├── chat-09095013f2caa58755e8a2d87eb66fc1\n│ │ ├── ...\n│ ├── summarize_descriptions\n│ │ ├── summarize-chat-v2-00e335e395c5ae2355ef3185793b440d\n│ │ ├── summarize-chat-v2-01c2694ab82c62924080f85e8253bb0a\n│ │ ├── summarize-chat-v2-03acd7bc38cf2fb24b77f69b016a288a\n│ │ ├── ...\n│ └── text_embedding\n│ ├── embedding-07cb902a76a26b6f98ca44c17157f47f\n│ ├── embedding-3e0be6bffd1c1ac6a091f5264858a2a1\n│ ├── ...\n├── input\n│ └── book.txt\n├── output\n│ └── 20240705-142536\n│ ├── artifacts\n│ │ ├── create_base_documents.parquet\n│ │ ├── create_base_entity_graph.parquet\n│ │ ├── create_base_extracted_entities.parquet\n│ │ ├── create_base_text_units.parquet\n│ │ ├── create_final_communities.parquet\n│ │ ├── create_final_community_reports.parquet\n│ │ ├── create_final_documents.parquet\n│ │ ├── create_final_entities.parquet\n│ │ ├── create_final_nodes.parquet\n│ │ ├── create_final_relationships.parquet\n│ │ ├── create_final_text_units.parquet\n│ │ ├── create_summarized_entities.parquet\n│ │ ├── join_text_units_to_entity_ids.parquet\n│ │ ├── join_text_units_to_relationship_ids.parquet\n│ │ └── stats.json\n│ └── reports\n│ ├── indexing-engine.log\n│ └── logs.json\n├── prompts\n│ ├── claim_extraction.txt\n│ ├── community_report.txt\n│ ├── entity_extraction.txt\n│ └── summarize_descriptions.txt\n└── settings.yaml\n")])]),e._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[e._v("1")]),s("br"),s("span",{staticClass:"line-number"},[e._v("2")]),s("br"),s("span",{staticClass:"line-number"},[e._v("3")]),s("br"),s("span",{staticClass:"line-number"},[e._v("4")]),s("br"),s("span",{staticClass:"line-number"},[e._v("5")]),s("br"),s("span",{staticClass:"line-number"},[e._v("6")]),s("br"),s("span",{staticClass:"line-number"},[e._v("7")]),s("br"),s("span",{staticClass:"line-number"},[e._v("8")]),s("br"),s("span",{staticClass:"line-number"},[e._v("9")]),s("br"),s("span",{staticClass:"line-number"},[e._v("10")]),s("br"),s("span",{staticClass:"line-number"},[e._v("11")]),s("br"),s("span",{staticClass:"line-number"},[e._v("12")]),s("br"),s("span",{staticClass:"line-number"},[e._v("13")]),s("br"),s("span",{staticClass:"line-number"},[e._v("14")]),s("br"),s("span",{staticClass:"line-number"},[e._v("15")]),s("br"),s("span",{staticClass:"line-number"},[e._v("16")]),s("br"),s("span",{staticClass:"line-number"},[e._v("17")]),s("br"),s("span",{staticClass:"line-number"},[e._v("18")]),s("br"),s("span",{staticClass:"line-number"},[e._v("19")]),s("br"),s("span",{staticClass:"line-number"},[e._v("20")]),s("br"),s("span",{staticClass:"line-number"},[e._v("21")]),s("br"),s("span",{staticClass:"line-number"},[e._v("22")]),s("br"),s("span",{staticClass:"line-number"},[e._v("23")]),s("br"),s("span",{staticClass:"line-number"},[e._v("24")]),s("br"),s("span",{staticClass:"line-number"},[e._v("25")]),s("br"),s("span",{staticClass:"line-number"},[e._v("26")]),s("br"),s("span",{staticClass:"line-number"},[e._v("27")]),s("br"),s("span",{staticClass:"line-number"},[e._v("28")]),s("br"),s("span",{staticClass:"line-number"},[e._v("29")]),s("br"),s("span",{staticClass:"line-number"},[e._v("30")]),s("br"),s("span",{staticClass:"line-number"},[e._v("31")]),s("br"),s("span",{staticClass:"line-number"},[e._v("32")]),s("br"),s("span",{staticClass:"line-number"},[e._v("33")]),s("br"),s("span",{staticClass:"line-number"},[e._v("34")]),s("br"),s("span",{staticClass:"line-number"},[e._v("35")]),s("br"),s("span",{staticClass:"line-number"},[e._v("36")]),s("br"),s("span",{staticClass:"line-number"},[e._v("37")]),s("br"),s("span",{staticClass:"line-number"},[e._v("38")]),s("br"),s("span",{staticClass:"line-number"},[e._v("39")]),s("br"),s("span",{staticClass:"line-number"},[e._v("40")]),s("br"),s("span",{staticClass:"line-number"},[e._v("41")]),s("br"),s("span",{staticClass:"line-number"},[e._v("42")]),s("br"),s("span",{staticClass:"line-number"},[e._v("43")]),s("br"),s("span",{staticClass:"line-number"},[e._v("44")]),s("br"),s("span",{staticClass:"line-number"},[e._v("45")]),s("br"),s("span",{staticClass:"line-number"},[e._v("46")]),s("br"),s("span",{staticClass:"line-number"},[e._v("47")]),s("br"),s("span",{staticClass:"line-number"},[e._v("48")]),s("br"),s("span",{staticClass:"line-number"},[e._v("49")]),s("br")])]),s("p",[e._v("这个文件中的很多文档都值得仔细研究，后续将结合代码详细说明。")]),e._v(" "),s("p",[e._v("此外，console中会打印很多运行日志，其中比较重要的一条就是完整的workflows，会涉及到完整pipeline的编排：")]),e._v(" "),s("div",{staticClass:"language-language-text line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("⠹ GraphRAG Indexer \n├── Loading Input (InputFileType.text) - 1 files loaded (0 filtered) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 0:00:00 0:00:00\n├── create_base_text_units\n├── create_base_extracted_entities\n├── create_summarized_entities\n├── create_base_entity_graph\n├── create_final_entities\n├── create_final_nodes\n├── create_final_communities\n├── join_text_units_to_entity_ids\n├── create_final_relationships\n├── join_text_units_to_relationship_ids\n├── create_final_community_reports\n├── create_final_text_units\n├── create_base_documents\n└── create_final_documents\n All workflows completed successfully.\n")])]),e._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[e._v("1")]),s("br"),s("span",{staticClass:"line-number"},[e._v("2")]),s("br"),s("span",{staticClass:"line-number"},[e._v("3")]),s("br"),s("span",{staticClass:"line-number"},[e._v("4")]),s("br"),s("span",{staticClass:"line-number"},[e._v("5")]),s("br"),s("span",{staticClass:"line-number"},[e._v("6")]),s("br"),s("span",{staticClass:"line-number"},[e._v("7")]),s("br"),s("span",{staticClass:"line-number"},[e._v("8")]),s("br"),s("span",{staticClass:"line-number"},[e._v("9")]),s("br"),s("span",{staticClass:"line-number"},[e._v("10")]),s("br"),s("span",{staticClass:"line-number"},[e._v("11")]),s("br"),s("span",{staticClass:"line-number"},[e._v("12")]),s("br"),s("span",{staticClass:"line-number"},[e._v("13")]),s("br"),s("span",{staticClass:"line-number"},[e._v("14")]),s("br"),s("span",{staticClass:"line-number"},[e._v("15")]),s("br"),s("span",{staticClass:"line-number"},[e._v("16")]),s("br"),s("span",{staticClass:"line-number"},[e._v("17")]),s("br")])]),s("h3",{attrs:{id:"_3-2-index"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-2-index"}},[e._v("#")]),e._v(" 3.2 Index")]),e._v(" "),s("p",[e._v("索引阶段整体看下来应该算是整个项目的核心，整体流程还是比较复杂的。 执行indexing的语句如下：")]),e._v(" "),s("div",{staticClass:"language-language-text line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("python -m graphrag.index --init --root ./ragtest\npython -m graphrag.index --root ./ragtest\n")])]),e._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[e._v("1")]),s("br"),s("span",{staticClass:"line-number"},[e._v("2")]),s("br")])]),s("blockquote"),e._v(" "),s("p",[s("img",{attrs:{src:"zhimg.com/v2-1e1314c43e194020d4bf007242addc76_r.jpg",alt:""}})]),e._v(" "),s("blockquote"),e._v(" "),s("p",[e._v("简单跟一下，发现实际调用的是 "),s("code",[e._v("graphrag/index/__main__.py")]),e._v(" 文件中的主函数，使用 "),s("code",[e._v("argparse")]),e._v(" 解析输入参数，实际调用的是 "),s("code",[e._v("graphrag/index/cli.py")]),e._v(" 中的 "),s("code",[e._v("index_cli")]),e._v(" 函数。")]),e._v(" "),s("p",[e._v("继续解读源码前，先简单看下相关函数的调用链路，如上图所示，其中灰色标记的函数是我们需要重点关注的。")]),e._v(" "),s("ul",[s("li",[s("code",[e._v("cli.py::index_cli()")]),e._v(" 函数首先根据用户输入参数，如 "),s("code",[e._v("--init")]),e._v(" ，确定是否需要初始化当前文件夹，这部分具体由 "),s("code",[e._v("cli.py::index_cli()")]),e._v(" 执行，其具体实现逻辑比较简单，检查目录下的一些配置、prompt、.env等文件是否存在，没有则创建，具体文件内容，就是上一节目录中展示的  "),s("code",[e._v("settings.yaml")]),e._v(" 、 "),s("code",[e._v("prompts")]),e._v(" 等。")]),e._v(" "),s("li",[e._v("真正执行indexing操作时，实际上会执行一个内部函数 "),s("code",[e._v("cli.py::index_cli()._run_workflow_async()")]),e._v(" ，主要会涉及到 "),s("code",[e._v("cli.py::_create_default_config()")]),e._v(" 与 "),s("code",[e._v("run.py::run_pipeline_with_config()")]),e._v(" 两个函数。")])]),e._v(" "),s("p",[e._v("限于篇幅，我们在此只讨论默认配置运行流程，大致梳理清楚相关逻辑后，可自行修改相关配置。")]),e._v(" "),s("ul",[s("li",[e._v("默认配置生成逻辑： "),s("code",[e._v("cli.py::_create_default_config()")]),e._v(" 首先检查根目录以及配置文件 "),s("code",[e._v("settings.yaml")]),e._v(" ，然后执行 "),s("code",[e._v("cli.py::_read_config_parameters()")]),e._v(" 读取系统配置，如llm、chunks、cache、storage等，接下来的操作比较关键，后续会根据当前参数创建一个pipeline的配置，具体代码位于  "),s("code",[e._v("create_pipeline_config.py::create_pipeline_config()")]),e._v(" ，这块绕了蛮久，可以说是整个项目中逻辑比较复杂的模块了。")]),e._v(" "),s("li",[e._v("如果深入 "),s("code",[e._v("create_pipeline_config.py::create_pipeline_config()")]),e._v(" 的代码，可以发现其核心逻辑如下：")])]),e._v(" "),s("div",{staticClass:"language-language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v("result = PipelineConfig(\n root_dir=settings.root_dir,\n input=_get_pipeline_input_config(settings),\n reporting=_get_reporting_config(settings),\n storage=_get_storage_config(settings),\n cache=_get_cache_config(settings),\n workflows=[\n *_document_workflows(settings，embedded_fields),\n *_text_unit_workflows(settings，covariates_enabled，embedded_fields),\n *_graph_workflows(settings，embedded_fields),\n *_community_workflows(settings，covariates_enabled，embedded_fields),\n *(_covariate_workflows(settings) if covariates_enabled else []),\n ],\n)\n")])]),e._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[e._v("1")]),s("br"),s("span",{staticClass:"line-number"},[e._v("2")]),s("br"),s("span",{staticClass:"line-number"},[e._v("3")]),s("br"),s("span",{staticClass:"line-number"},[e._v("4")]),s("br"),s("span",{staticClass:"line-number"},[e._v("5")]),s("br"),s("span",{staticClass:"line-number"},[e._v("6")]),s("br"),s("span",{staticClass:"line-number"},[e._v("7")]),s("br"),s("span",{staticClass:"line-number"},[e._v("8")]),s("br"),s("span",{staticClass:"line-number"},[e._v("9")]),s("br"),s("span",{staticClass:"line-number"},[e._v("10")]),s("br"),s("span",{staticClass:"line-number"},[e._v("11")]),s("br"),s("span",{staticClass:"line-number"},[e._v("12")]),s("br"),s("span",{staticClass:"line-number"},[e._v("13")]),s("br"),s("span",{staticClass:"line-number"},[e._v("14")]),s("br")])]),s("p",[e._v("这段代码的基本逻辑就是根据不同的功能生成完整的workflow序列，此处需要注意的是这里并不考虑workflow之间的依赖关系，单纯基于 "),s("code",[e._v("workflows/v1")]),e._v(" 目录下的各workflow的模板生成一系列的workflow。")]),e._v(" "),s("ul",[s("li",[e._v("Pipeline执行逻辑： "),s("code",[e._v("run.py::run_pipeline_with_config()")]),e._v(" 首先根据 "),s("code",[e._v("load_pipeline_config.py::load_pipeline_config()")]),e._v(" 加载现有pipeline的配置(由上一步中 "),s("code",[e._v("cli.py::_create_default_config()")]),e._v(" 生成)，然后创建目标文件中的其他子目录，如cache，storage，input，output等(详见上一节目录结构树)，然后再利用 "),s("code",[e._v("run.py::run_pipeline()")]),e._v(" 依次执行每一个工作流，并返回相应结果。")])]),e._v(" "),s("p",[e._v("这里有必要再单独说明一下 "),s("code",[e._v("run.py::run_pipeline()")]),e._v(" ，该函数用于真正的执行所有pipeline，其核心逻辑包含以下两部分：")]),e._v(" "),s("ul",[s("li",[e._v("加载workflows： "),s("code",[e._v("workflows/load.py::load_workflows()")]),e._v(" ，除了常规工作流的创建外，还会涉及到拓扑排序问题。")]),e._v(" "),s("li",[s("code",[e._v("workflows/load.py::create_workflow()")]),e._v(" ：利用已有模板，创建不同的工作流。")]),e._v(" "),s("li",[s("code",[e._v("graphlib::topological_sort()")]),e._v(" ：根据workflow之间的依赖关系，计算DAG的拓扑排序、")]),e._v(" "),s("li",[e._v("进一步执行 "),s("code",[e._v("inject_workflow_data_dependencies()")]),e._v(" 、 "),s("code",[e._v("write_workflow_stats()")]),e._v(" 、 "),s("code",[e._v("emit_workflow_output")]),e._v(" 等操作，分别用于依赖注入，数据写入以及保存，真正的 "),s("code",[e._v("workflow.run")]),e._v(" 操作会在 "),s("code",[e._v("write_workflow_stats()")]),e._v(" 之前执行，此处的核心逻辑可参考以下代码。")])]),e._v(" "),s("div",{staticClass:"language-language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v('await dump_stats()\nfor workflow_to_run in workflows_to_run:\n # Try to flush out any intermediate dataframes\n gc.collect()\n workflow = workflow_to_run.workflow\n workflow_name: str = workflow.name\n last_workflow = workflow_name\n log.info("Running workflow: %s..."，workflow_name)\n if is_resume_run and await storage.has(\n f"{workflow_to_run.workflow.name}.parquet"\n ):\n log.info("Skipping %s because it already exists"，workflow_name)\n continue\n stats.workflows[workflow_name] = {"overall": 0.0}\n await inject_workflow_data_dependencies(workflow)\n workflow_start_time = time.time()\n result = await workflow.run(context，callbacks)\n await write_workflow_stats(workflow，result，workflow_start_time)\n # Save the output from the workflow\n output = await emit_workflow_output(workflow)\n yield PipelineRunResult(workflow_name，output，None)\n output = None\n workflow.dispose()\n workflow = None\nstats.total_runtime = time.time() - start_time\nawait dump_stats()\n')])]),e._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[e._v("1")]),s("br"),s("span",{staticClass:"line-number"},[e._v("2")]),s("br"),s("span",{staticClass:"line-number"},[e._v("3")]),s("br"),s("span",{staticClass:"line-number"},[e._v("4")]),s("br"),s("span",{staticClass:"line-number"},[e._v("5")]),s("br"),s("span",{staticClass:"line-number"},[e._v("6")]),s("br"),s("span",{staticClass:"line-number"},[e._v("7")]),s("br"),s("span",{staticClass:"line-number"},[e._v("8")]),s("br"),s("span",{staticClass:"line-number"},[e._v("9")]),s("br"),s("span",{staticClass:"line-number"},[e._v("10")]),s("br"),s("span",{staticClass:"line-number"},[e._v("11")]),s("br"),s("span",{staticClass:"line-number"},[e._v("12")]),s("br"),s("span",{staticClass:"line-number"},[e._v("13")]),s("br"),s("span",{staticClass:"line-number"},[e._v("14")]),s("br"),s("span",{staticClass:"line-number"},[e._v("15")]),s("br"),s("span",{staticClass:"line-number"},[e._v("16")]),s("br"),s("span",{staticClass:"line-number"},[e._v("17")]),s("br"),s("span",{staticClass:"line-number"},[e._v("18")]),s("br"),s("span",{staticClass:"line-number"},[e._v("19")]),s("br"),s("span",{staticClass:"line-number"},[e._v("20")]),s("br"),s("span",{staticClass:"line-number"},[e._v("21")]),s("br"),s("span",{staticClass:"line-number"},[e._v("22")]),s("br"),s("span",{staticClass:"line-number"},[e._v("23")]),s("br"),s("span",{staticClass:"line-number"},[e._v("24")]),s("br"),s("span",{staticClass:"line-number"},[e._v("25")]),s("br"),s("span",{staticClass:"line-number"},[e._v("26")]),s("br")])]),s("p",[e._v("根据以上信息，我们可以大致梳理出索引环节的完整工作流。")]),e._v(" "),s("ul",[s("li",[e._v("初始化：生成必要的配置文件，缓存，input/output目录等。")]),e._v(" "),s("li",[e._v("索引：根据配置文件，利用workflow模板创建一系列的pipeline，并依据依赖关系，调整实际执行顺序，再依次执行。")])]),e._v(" "),s("h3",{attrs:{id:"_3-3-workflow"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-3-workflow"}},[e._v("#")]),e._v(" 3.3 Workflow")]),e._v(" "),s("p",[e._v("截至目前，我们实际上还没有真正分析index阶段的业务逻辑，只是搞清楚了GraphRAG内置的这套pipeline编排系统该如何工作。这里以 "),s("code",[e._v("index/workflows/v1/create_final_entities.py")]),e._v(" 为例，一起看下具体的一个workflow是如何运行的。")]),e._v(" "),s("ul",[s("li",[e._v("DataShaper")])]),e._v(" "),s("p",[e._v("讨论workflow之前，先简单了解下项目使用的另一个框架: "),s("a",{attrs:{href:"https://github.com/microsoft/datashaper",target:"_blank",rel:"noopener noreferrer"}},[e._v("DataShaper"),s("OutboundLink")],1),e._v(" 是微软开源的一款用于执行工作流处理的库，内置了很多组件(专业名词叫做Verb). 通俗来讲，DataShaper就像一条流水线，每一步定义了作用于input数据的一种操作，类似pytorch图像变换中clip、rotate、scale等操作，如果还是不能理解，建议直接跑一下官方文档中的demo程序 "),s("code",[e._v("examples/single_verb")]),e._v(" ，应该就大致清楚怎么回事了。从功能上来讲，个人感觉有点像Prefect。")]),e._v(" "),s("ul",[s("li",[e._v("知识图谱构建")])]),e._v(" "),s("p",[e._v("对应的工作流是 "),s("code",[e._v("create_final_entities.py")]),e._v(" ，翻阅源码可以发现，该workflow会依赖于 "),s("code",[e._v("workflow:create_base_extracted_entities")]),e._v(" ，同时定义了 "),s("code",[e._v("cluster_graph")]),e._v(" 、 "),s("code",[e._v("embed_graph")]),e._v(" 等操作，其中 "),s("code",[e._v("cluster_graph")]),e._v(" 采用了leiden策略，具体代码位于 "),s("code",[e._v("index/verbs/graph/clustering/cluster_graph.py")]),e._v(" 。")]),e._v(" "),s("div",{staticClass:"language-language-python line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v('from datashaper import TableContainer，VerbCallbacks，VerbInput，progress_iterable，verb\n@verb(name="cluster_graph")\ndef cluster_graph(\n input: VerbInput,\n callbacks: VerbCallbacks,\n strategy: dict[str，Any],\n column: str,\n to: str,\n level_to: str | None = None,\n **_kwargs,\n) -> TableContainer:\n')])]),e._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[e._v("1")]),s("br"),s("span",{staticClass:"line-number"},[e._v("2")]),s("br"),s("span",{staticClass:"line-number"},[e._v("3")]),s("br"),s("span",{staticClass:"line-number"},[e._v("4")]),s("br"),s("span",{staticClass:"line-number"},[e._v("5")]),s("br"),s("span",{staticClass:"line-number"},[e._v("6")]),s("br"),s("span",{staticClass:"line-number"},[e._v("7")]),s("br"),s("span",{staticClass:"line-number"},[e._v("8")]),s("br"),s("span",{staticClass:"line-number"},[e._v("9")]),s("br"),s("span",{staticClass:"line-number"},[e._v("10")]),s("br"),s("span",{staticClass:"line-number"},[e._v("11")]),s("br")])]),s("p",[e._v("可以看出，实际上就是加了一个verb装饰器而已，进一步跟进 strategy 的实现可以发现，这里的leiden算法实际上也是源自另一个图算法库： "),s("a",{attrs:{href:"https://github.com/graspologic-org/graspologic",target:"_blank",rel:"noopener noreferrer"}},[e._v("graspologic-org/graspologic: Python package for graph statistics (github.com)"),s("OutboundLink")],1),e._v("。")]),e._v(" "),s("ul",[s("li",[e._v("Pipeline")])]),e._v(" "),s("p",[e._v("搞清楚了上述workflow的执行逻辑，再根据上节最后提到的编排日志，或者 "),s("code",[e._v("artifacts/stats.json")]),e._v(" 文件，就可以整理出完整工作流了. 官方文档也放出了非常详细的说明，参见"),s("a",{attrs:{href:"https://microsoft.github.io/graphrag/posts/index/1-default_dataflow/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Indexing Dataflow (microsoft.github.io)"),s("OutboundLink")],1),e._v(" 不过我这边依据源码提取出来的pipeline好像还是有些差异的，有做过相关工作的可以留言探讨下。")]),e._v(" "),s("h3",{attrs:{id:"_3-4-query"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-query"}},[e._v("#")]),e._v(" 3.4 Query")]),e._v(" "),s("p",[e._v("查询阶段的pipeline相对而言要简单些，执行query的语句如下：")]),e._v(" "),s("div",{staticClass:"language-language-text line-numbers-mode"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[e._v('# Global search\npython -m graphrag.query \\\n--root ./ragtest \\\n--method global \\\n"What are the top themes in this story?"\n# Local search\npython -m graphrag.query \\\n--root ./ragtest \\\n--method local \\\n"Who is Scrooge，and what are his main relationships?"\n')])]),e._v(" "),s("div",{staticClass:"line-numbers-wrapper"},[s("span",{staticClass:"line-number"},[e._v("1")]),s("br"),s("span",{staticClass:"line-number"},[e._v("2")]),s("br"),s("span",{staticClass:"line-number"},[e._v("3")]),s("br"),s("span",{staticClass:"line-number"},[e._v("4")]),s("br"),s("span",{staticClass:"line-number"},[e._v("5")]),s("br"),s("span",{staticClass:"line-number"},[e._v("6")]),s("br"),s("span",{staticClass:"line-number"},[e._v("7")]),s("br"),s("span",{staticClass:"line-number"},[e._v("8")]),s("br"),s("span",{staticClass:"line-number"},[e._v("9")]),s("br"),s("span",{staticClass:"line-number"},[e._v("10")]),s("br")])]),s("p",[e._v("这里需要注意的是有Global/Local search两种模式。还是先生成函数调用关系图，对整体结构能有个大致了解。")]),e._v(" "),s("blockquote"),e._v(" "),s("p",[s("img",{attrs:{src:"zhimg.com/v2-e6d75cb4a31d9f1ffcd3104b491e41da_r.jpg",alt:""}})]),e._v(" "),s("blockquote"),e._v(" "),s("p",[s("code",[e._v("graphrag/query/__main__.py")]),e._v(" 中的主函数会依据参数不同，分别路由至 "),s("code",[e._v("cli::run_local_search()")]),e._v(" 以及 "),s("code",[e._v("cli::run_global_search()")]),e._v(" 。")]),e._v(" "),s("h3",{attrs:{id:"_3-4-1-global-search"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-1-global-search"}},[e._v("#")]),e._v(" 3.4.1 Global Search")]),e._v(" "),s("p",[s("code",[e._v("cli::run_global_search()")]),e._v(" 主要调用了 "),s("code",[e._v("factories.py::get_global_search_engine()")]),e._v(" 函数，返回一个详细定义的 "),s("code",[e._v("GlobalSearch")]),e._v(" 类，进一步跟进去，发现该类跟 "),s("code",[e._v("LocalSearch")]),e._v(" 类相似，都是基于工厂模式创建，其核心方法为 "),s("code",[e._v("structured_search/global_search/search.py::GlobalSearch.asearch()")]),e._v(" ，具体使用了map-reduce方法，首先使用大模型并行地为每个社区的summary生成答案，然后再汇总所有答案生成最终结果，此处建议参考map/reduce的相关prompts，作者给出了非常详细的说明。也正是因为这种map-reduce的机制，导致global search对token的消耗量极大。")]),e._v(" "),s("h3",{attrs:{id:"_3-4-2-local-search"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_3-4-2-local-search"}},[e._v("#")]),e._v(" 3.4.2 Local Search")]),e._v(" "),s("p",[e._v("与全局搜索类似， "),s("code",[e._v("cli::run_local_search()")]),e._v(" 函数主要也是调用了 "),s("code",[e._v("factories.py::get_local_search_engine()")]),e._v(" ，返回一个 "),s("code",[e._v("LocalSearch")]),e._v(" 类，这里的 "),s("code",[e._v("asearch()")]),e._v(" 相对比较简单，会直接根据上下文给出回复，这种模式更接近于常规的RAG语义检索策略，所消耗的Token也比较少。 与全局搜索不同的地方在于，Local 模式综合了nodes，community_reports，text_units，relationships，entities，covariates等多种源数据，这一点在官方文档中也给出了非常详细的说明，不再赘述。")]),e._v(" "),s("h3",{attrs:{id:"_4-一些思考"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_4-一些思考"}},[e._v("#")]),e._v(" 4. 一些思考")]),e._v(" "),s("ul",[s("li",[e._v("GraphRAG最核心的卖点就在于一定程度上解决了聚焦于查询的总结性(QueryFocused Summarization，QFS)任务，这一点就个人了解到的，应该还是首创，在此之前，思路上最接近的应该就是 "),s("a",{attrs:{href:"https://github.com/parthsarthi03/raptor",target:"_blank",rel:"noopener noreferrer"}},[e._v("parthsarthi03/raptor: The official implementation of RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval (github.com)"),s("OutboundLink")],1),e._v("，不过后者并非针对知识图谱。QFS与Multi-Hop Q&A应该是现阶段RAG系统都暂时无法解决的难点，但是对于很多场景，尤其是数据分析领域，却有着广泛的应用. 虽然当下GraphRAG的使用成本还很高，不过至少提供了一种可能性。")]),e._v(" "),s("li",[e._v("此外，个人感觉相较于一般的知识图谱RAG项目，GraphRAG给我印象更为深刻的，是内置了一套相对完整的工作流编排系统，这一点在其他RAG框架中还不多见. 这可能也是后续一个值得深挖的方向，基于模板定义好大部分工作流，提供少部分的配置灵活性，每一个环节都可控可追溯，而不是一味地让大模型执行所有操作。")])]),e._v(" "),s("p",[e._v("与之相对地，常规RAG部分，比如embedding，retrieval等环节反而没有太多需要讨论的地方，尽管加了个社区检测算法。")]),e._v(" "),s("ul",[s("li",[e._v("当然，本项目在知识图谱的处理颗粒度上也做得很细，比如社区检测的 leiden 算法，综合多源数据的 local search等. 一个有意思的点在于，项目中实体抽取相较于常规的一些基于Pydantic的思路，目前已经是完全采用大模型实现了，并且在三元组的schema方面也未设置任何约束，作者还简单解释了下，因为总是要做相似性聚类的，所以每次大模型抽取即使有些差异，最终社区的生成也不会有很大影响，这一点说实话在鲁棒性方面确实是很大的提升 。")]),e._v(" "),s("li",[e._v("我个人觉得目前的GraphRAG也仍旧还有很多值得改进的地方，比如搞了很多让人云里雾里的名词，诸如 Emit，Claim，Verbs，Reporting 之类，同时夹带私货，用了一些微软自家的相对比较小众的库，这也进一步加大了理解上的难度，此外，模块化方面应该也有待加强，尤其是OpenAI那块，耦合严重。")])]),e._v(" "),s("p",[e._v("综合来看，微软本次放出的GraphRAG框架确实有不少干货，值得花些时间去仔细研读和思考。")]),e._v(" "),s("h3",{attrs:{id:"_5-reference"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#_5-reference"}},[e._v("#")]),e._v(" 5. Reference")]),e._v(" "),s("ul",[s("li",[s("a",{attrs:{href:"https://microsoft.github.io/graphrag/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Welcome to GraphRAG (microsoft.github.io)"),s("OutboundLink")],1)]),e._v(" "),s("li",[s("a",{attrs:{href:"https://www.youtube.com/watch?v=r09tJfON6kE",target:"_blank",rel:"noopener noreferrer"}},[e._v("GraphRAG: LLM-Derived Knowledge Graphs for RAG (youtube.com)"),s("OutboundLink")],1)]),e._v(" "),s("li",[s("a",{attrs:{href:"https://news.ycombinator.com/item?id=40857174",target:"_blank",rel:"noopener noreferrer"}},[e._v("GraphRAG is now on GitHub | Hacker News (ycombinator.com)"),s("OutboundLink")],1)]),e._v(" "),s("li",[s("a",{attrs:{href:"https://www.reddit.com/r/LocalLLaMA/comments/1du6c8d/graphrag_ollama_intelligent_search_of_local_data/",target:"_blank",rel:"noopener noreferrer"}},[e._v("GraphRAG & Ollama - intelligent Search of local data : r/LocalLLaMA (reddit.com)"),s("OutboundLink")],1)]),e._v(" "),s("li",[s("a",{attrs:{href:"https://www.reddit.com/r/LocalLLaMA/comments/1az1ies/graphrag_on_narrative_private_data/",target:"_blank",rel:"noopener noreferrer"}},[e._v("GraphRAG on narrative private data : r/LocalLLaMA (reddit.com)"),s("OutboundLink")],1)])])])}),[],!1,null,null,null);a.default=t.exports}}]);