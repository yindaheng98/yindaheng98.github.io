(window.webpackJsonp=window.webpackJsonp||[]).push([[190],{867:function(t,s,a){"use strict";a.r(s);var i=a(4),e=Object(i.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[a("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/631784361",target:"_blank",rel:"noopener noreferrer"}},[t._v("原文在此"),a("OutboundLink")],1)]),t._v(" "),a("h2",{attrs:{id:"前言"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#前言"}},[t._v("#")]),t._v(" 前言")]),t._v(" "),a("p",[t._v("可微渲染和神经渲染是近年来大热的研究主题，不过作为新兴领域，相关的资料都零零散散，通常也需要对计算机图形学、机器学习等方面都有一些基础知识才能有一个较好的认识。本文是作者以一位计算机图形学学习者的角度，对现有资料的一些整理和理解。涉及的一些知识也尽可能地引用其他文章做一个补充理解。希望在阅读完本文后，大家能对可微渲染和神经渲染有一个较为清晰的认知。作者才疏学浅，如果有任何问题欢迎在评论区交流。")]),t._v(" "),a("p",[t._v("最近发现还有一篇文章也介绍地比较全面，是从工业界角度出发的，本篇文章试图更多地从学术理论的角度去看待问题。\n"),a("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/631784361",target:"_blank",rel:"noopener noreferrer"}},[a("OutboundLink")],1),t._v("\n图片及素材取自网络、论文以及视频截图，如有侵权请联系作者更换或删除。")]),t._v(" "),a("h2",{attrs:{id:"为什么要使用可微渲染"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#为什么要使用可微渲染"}},[t._v("#")]),t._v(" 为什么要使用可微渲染")]),t._v(" "),a("ol",[a("li",[t._v("解决 "),a("strong",[t._v("逆渲染")]),t._v(" 问题：逆渲染是与渲染相反的过程，该过程从图片中获得物体的几何表示、材质、场景光照和相机参数等。逆渲染是个非常困难的不适定问题，为了正则化这个不适定问题，通常使用逆渲染对象的先验知识，比如对于人体组成部分（人脸、人体和人手），之前论文提出的方法可能会提前给定好一个标准结构（大众脸型，预先定好骨骼关节等），后续再从图像上学习到特征后对标准结构进行微调。借助可微渲染过程中计算的导数，我们可以解决更加宽泛的逆渲染问题。")]),t._v(" "),a("li",[t._v("将 "),a("strong",[t._v("前向渲染")]),t._v(" 过程集成到 "),a("strong",[t._v("概率推理（probabilistic inference）")]),t._v(" 和 "),a("strong",[t._v("机器学习")]),t._v(" 等更大的优化系统中。比如，在训练时能够反向传播梯度。")]),t._v(" "),a("li",[t._v("上述1.2点在计算机视觉，计算机图形学，计算成像（Computational imaging），VR/AR等领域中有数量庞大的应用。")])]),t._v(" "),a("h2",{attrs:{id:"从传统管线出发"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#从传统管线出发"}},[t._v("#")]),t._v(" 从传统管线出发")]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-5c8f4949f9bc3adc83670ee7c8bb59e9_r.jpg",alt:"对传统OpenGL渲染管线的关于是否可微的分析"}})]),t._v(" "),a("p",[t._v("我们从一个比较传统的OpenGL渲染管线出发，思考一下到底是其中的哪些步骤 "),a("strong",[t._v("不可微")]),t._v(" 。")]),t._v(" "),a("ol",[a("li",[t._v("顶点着色器：对顶点进行各类操作，包括平移、缩放、旋转和投影，本质上都是矩阵乘法，均是线性操作，所以天然可微。")]),t._v(" "),a("li",[t._v("图元装配：把顶点装配成不同的几何结构（三角形、线段等）")]),t._v(" "),a("li",[t._v("几何着色器：可选阶段，一般用于产生新图元或做LOD操作。")]),t._v(" "),a("li",[t._v("光栅化：通过将几何图元（如线段、三角形）映射到像素网格，对每个像素的采样和插值来确定像素的颜色。由于这是一个离散的过程，光栅化步骤不是在连续的参数空间上操作，因此 "),a("strong",[t._v("不具备可微性")]),t._v(" 。")]),t._v(" "),a("li",[t._v("片段着色器：首先找到片段所在的三角形并计算片段中心的重心坐标, 通过重心插值把顶点的属性赋给每个片段。对许多常用模型来说都是可微的，但也可能会包含不可微的部分。")]),t._v(" "),a("li",[t._v("测试与混合操作，包括深度测试、模板测试和颜色混合等。这些操作都是非线性操作，求导很困难，因此通常被认为是 "),a("strong",[t._v("不可微")]),t._v(" 的。")])]),t._v(" "),a("p",[t._v("可以发现只有4、6中包含有必定不可微的部分。基于光栅化的可微渲染也是解决这两个问题为主。")]),t._v(" "),a("h3",{attrs:{id:"从传统正向渲染到可微渲染"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#从传统正向渲染到可微渲染"}},[t._v("#")]),t._v(" 从传统正向渲染到可微渲染")]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-8a68f64a7f5678481907ce4be134c524_r.jpg",alt:"常见的带有可微渲染器的优化系统框架"}})]),t._v(" "),a("p",[a("strong",[t._v("传统的渲染")]),t._v(" ：把几何、光照、材质和相机位置等一系列输入传给光栅化或者是光追的渲染器，渲染器经过一系列管线操作后，输出一张图片。")]),t._v(" "),a("p",[a("strong",[t._v("可微的渲染")]),t._v(" ：计算渲染过程中的导数，让渲染过程变得可微。然后通过图像和ground truth之间的差异，计算目标函数，得到loss后，对loss求导得到梯度，通过梯度反向传播来优化各种场景参数。")]),t._v(" "),a("p",[t._v("那么我们如何修改传统渲染管线使得整个渲染过程都变得可微分呢？这里首先跟随论文[1]的视角，从基于局部光照模型和全局光照模型这两个角度去看待这个问题。")]),t._v(" "),a("h2",{attrs:{id:"基于局部光照模型的可微渲染方法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基于局部光照模型的可微渲染方法"}},[t._v("#")]),t._v(" 基于局部光照模型的可微渲染方法")]),t._v(" "),a("ol",[a("li",[t._v("使用近似的方法，计算近似导数用于反向传播")])]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-261d04edab6359a1cd117f5ff328746d_r.jpg",alt:"OpenDR的流程图"}})]),t._v(" "),a("p",[t._v("OpenDR提出了一种对渲染过程求近似导数的方法，限定了计算颜色的过程，要求颜色逐顶点确定的，顶点的颜色在光栅化之前已经计算完成。之后片段着色器只是对顶点颜色进行插值得到片段的颜色，但无需修改光栅化的过程。")]),t._v(" "),a("p",[t._v("如图所示，为了求得 f 对 V、A、C 的导数，由链式法则，我们总共需要求  "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("f")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("A")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial f}{\\partial A}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.277216em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.9322159999999999em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight"},[t._v("A")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.446108em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.10764em"}},[t._v("f")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])]),t._v(" "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("f")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("U")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial f}{\\partial U}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.277216em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.9322159999999999em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.10903em"}},[t._v("U")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.446108em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.10764em"}},[t._v("f")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])]),t._v(" "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("U")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("V")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial U}{\\partial V}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.2251079999999999em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.8801079999999999em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.22222em"}},[t._v("V")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.394em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.10903em"}},[t._v("U")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])]),t._v(" "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("U")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("C")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial U}{\\partial C}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.2251079999999999em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.8801079999999999em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.07153em"}},[t._v("C")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.394em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.10903em"}},[t._v("U")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])]),t._v(" "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("V")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("A")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial V}{\\partial A}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.2251079999999999em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.8801079999999999em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight"},[t._v("A")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.394em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.22222em"}},[t._v("V")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])]),t._v("  五组偏导数。")]),t._v(" "),a("p",[t._v("其中  "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("A")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("V")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial A}{\\partial V}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.2251079999999999em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.8801079999999999em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.22222em"}},[t._v("V")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.394em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight"},[t._v("A")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])]),t._v("  的可微性是由用户定义的计算颜色的函数的可导性决定的，通常这个函数是初等函数，可微。")]),t._v(" "),a("p",[t._v("而  "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("U")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("V")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial U}{\\partial V}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.2251079999999999em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.8801079999999999em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.22222em"}},[t._v("V")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.394em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.10903em"}},[t._v("U")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])]),t._v("  和  "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("U")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("C")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial U}{\\partial C}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.2251079999999999em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.8801079999999999em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.07153em"}},[t._v("C")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.394em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.10903em"}},[t._v("U")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])]),t._v("  是顶点变换，天然可微。")]),t._v(" "),a("p",[t._v("那么只剩下右边的两个偏导数，对于  "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("f")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("A")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial f}{\\partial A}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.277216em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.9322159999999999em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight"},[t._v("A")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.446108em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.10764em"}},[t._v("f")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])]),t._v("  ，由于 OpenDR 对顶点颜色进行插值得到片段的颜色，所以像素对顶点颜色的导数就是该像素对应的可见片段在其三角形的重心坐标，只需在正向过程中保存每个片段的重心坐标以及每个像素对应的可见片段即可。")]),t._v(" "),a("p",[t._v("对于  "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("f")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("U")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial f}{\\partial U}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.277216em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.9322159999999999em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.10903em"}},[t._v("U")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.446108em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.10764em"}},[t._v("f")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])]),t._v("  ，OpenDR根据像素跟遮挡边界的关系，把像素分为了内部像素和边界像素。对于不同种类的像素使用了不同的滤波核进行滤波操作来求得近似导数。")]),t._v(" "),a("p",[t._v("关于OpenDR，具体可以参考这篇文章："),a("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/584510853",target:"_blank",rel:"noopener noreferrer"}},[t._v("理解可微渲染 (一) ：OpenDR - 知乎 (zhihu.com)"),a("OutboundLink")],1)]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[t._v("改编传统渲染模型，让像素对顶点可导。改编后的渲染方法依然拥有渲染的能力，渲染结果不发生较大变化，但过程完全可微，可以求得精确导数。通常改编其中光栅化的步骤。")])]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-db27a65c911a8fae3353425ef531516f_r.jpg",alt:"SoftRas的渲染管线"}})]),t._v(" "),a("p",[t._v("和OpenDR类似，SoftRas也是通过逐顶点光照和顶点变换保证左边的几组偏导数可微。")]),t._v(" "),a("p",[t._v("对于右边的几组偏导数，SoftRas使用概率分布的方法改编了光栅化、测试与混合这两个步骤。也就是说传统的深度测试、光栅化这种非0即1的操作，都变成了0到1之间按概率分布的值，从而保证了可微。")]),t._v(" "),a("h2",{attrs:{id:"基于全局光照模型的可微渲染"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基于全局光照模型的可微渲染"}},[t._v("#")]),t._v(" 基于全局光照模型的可微渲染")]),t._v(" "),a("p",[t._v("基于全局光照（Global Illumination, GI）模型的可微渲染，优点是能够对间接光照求导，渲染结果更具真实感，缺点是时间开销非常大。")]),t._v(" "),a("p",[t._v("路径追踪是基于GI的可微渲染方法的基础（关于路径追踪此处不再过多展开），基于GI的可微渲染所面临主要的 "),a("strong",[t._v("难点")]),t._v(" ：")]),t._v(" "),a("ul",[a("li",[t._v("需要对渲染方程（积分方程/路径积分）的解进行微分，而这些解和场景参数之间的关系可能是非常复杂的")]),t._v(" "),a("li",[t._v("需要处理非常多的梯度矩阵（可能  "),a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mn",[t._v("1")]),a("msup",[a("mn",[t._v("0")]),a("mn",[t._v("12")])],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("10^{12}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"0.8141079999999999em","vertical-align":"0em"}}),a("span",{staticClass:"mord"},[t._v("1")]),a("span",{staticClass:"mord"},[a("span",{staticClass:"mord"},[t._v("0")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.8141079999999999em"}},[a("span",{staticStyle:{top:"-3.063em","margin-right":"0.05em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight"},[t._v("1")]),a("span",{staticClass:"mord mtight"},[t._v("2")])])])])])])])])])])])]),t._v("  或更多），因为一张图片可能有几百万像素，而场景参数也可能会有百万级别的规模，矩阵数量已经多到已经不好存储的地步。")])]),t._v(" "),a("p",[a("strong",[t._v("必须要注意的问题")]),t._v(" ：")]),t._v(" "),a("ul",[a("li",[t._v("确保每一步的正确性：对于整个系统而言，每一步微小的误差累计后都是巨大的差别，所以直接把自动微分丢给Path Tracer是不可行的")]),t._v(" "),a("li",[t._v("PDF是否可微？实际上两种情况都有可能。")]),t._v(" "),a("li",[t._v("渲染方程中函数的不连续性")])]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-c0005be2c5a82ee93ae53184019034bb_r.jpg",alt:"不连续性的来源"}})]),t._v(" "),a("p",[a("strong",[t._v("为什么不使用差分？")])]),t._v(" "),a("p",[t._v("如果对高等数学有一些了解的话，可以得知通过差分能够近似微分：")]),t._v(" "),a("p",[a("span",{staticClass:"katex"},[a("span",{staticClass:"katex-mathml"},[a("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[a("semantics",[a("mrow",[a("mfrac",[a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("mi",[t._v("F")])],1),a("mrow",[a("mi",{attrs:{mathvariant:"normal"}},[t._v("∂")]),a("msub",[a("mi",[t._v("θ")]),a("mi",[t._v("i")])],1)],1)],1),a("mo",[t._v("≈")]),a("mfrac",[a("mrow",[a("mi",[t._v("F")]),a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("θ")]),a("mo",[t._v("+")]),a("mi",[t._v("ϵ")]),a("msub",[a("mi",[t._v("e")]),a("mi",[t._v("i")])],1),a("mo",{attrs:{stretchy:"false"}},[t._v(")")]),a("mo",[t._v("−")]),a("mi",[t._v("F")]),a("mo",{attrs:{stretchy:"false"}},[t._v("(")]),a("mi",[t._v("θ")]),a("mo",[t._v("−")]),a("mi",[t._v("ϵ")]),a("msub",[a("mi",[t._v("e")]),a("mi",[t._v("i")])],1),a("mo",{attrs:{stretchy:"false"}},[t._v(")")])],1),a("mrow",[a("mn",[t._v("2")]),a("mi",[t._v("ϵ")])],1)],1)],1),a("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("\\frac{\\partial F}{\\partial \\theta_i} \\approx \\frac{F(\\theta+\\epsilon e_i) - F(\\theta-\\epsilon e_i)}{2\\epsilon}")])],1)],1)],1),a("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.325208em","vertical-align":"-0.44509999999999994em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.8801079999999999em"}},[a("span",{staticStyle:{top:"-2.655em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.02778em"}},[t._v("θ")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.3280857142857143em"}},[a("span",{staticStyle:{top:"-2.357em","margin-left":"-0.02778em","margin-right":"0.07142857142857144em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.5em"}}),a("span",{staticClass:"sizing reset-size3 size1 mtight"},[a("span",{staticClass:"mord mathdefault mtight"},[t._v("i")])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.143em"}},[a("span")])])])])])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.394em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight",staticStyle:{"margin-right":"0.05556em"}},[t._v("∂")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.13889em"}},[t._v("F")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.44509999999999994em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}}),a("span",{staticClass:"mrel"},[t._v("≈")]),a("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}})]),a("span",{staticClass:"base"},[a("span",{staticClass:"strut",staticStyle:{height:"1.355em","vertical-align":"-0.345em"}}),a("span",{staticClass:"mord"},[a("span",{staticClass:"mopen nulldelimiter"}),a("span",{staticClass:"mfrac"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"1.01em"}},[a("span",{staticStyle:{top:"-2.6550000000000002em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mtight"},[t._v("2")]),a("span",{staticClass:"mord mathdefault mtight"},[t._v("ϵ")])])])]),a("span",{staticStyle:{top:"-3.23em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"frac-line",staticStyle:{"border-bottom-width":"0.04em"}})]),a("span",{staticStyle:{top:"-3.485em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"3em"}}),a("span",{staticClass:"sizing reset-size6 size3 mtight"},[a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.13889em"}},[t._v("F")]),a("span",{staticClass:"mopen mtight"},[t._v("(")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.02778em"}},[t._v("θ")]),a("span",{staticClass:"mbin mtight"},[t._v("+")]),a("span",{staticClass:"mord mathdefault mtight"},[t._v("ϵ")]),a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mathdefault mtight"},[t._v("e")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.3280857142857143em"}},[a("span",{staticStyle:{top:"-2.357em","margin-left":"0em","margin-right":"0.07142857142857144em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.5em"}}),a("span",{staticClass:"sizing reset-size3 size1 mtight"},[a("span",{staticClass:"mord mathdefault mtight"},[t._v("i")])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.143em"}},[a("span")])])])])]),a("span",{staticClass:"mclose mtight"},[t._v(")")]),a("span",{staticClass:"mbin mtight"},[t._v("−")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.13889em"}},[t._v("F")]),a("span",{staticClass:"mopen mtight"},[t._v("(")]),a("span",{staticClass:"mord mathdefault mtight",staticStyle:{"margin-right":"0.02778em"}},[t._v("θ")]),a("span",{staticClass:"mbin mtight"},[t._v("−")]),a("span",{staticClass:"mord mathdefault mtight"},[t._v("ϵ")]),a("span",{staticClass:"mord mtight"},[a("span",{staticClass:"mord mathdefault mtight"},[t._v("e")]),a("span",{staticClass:"msupsub"},[a("span",{staticClass:"vlist-t vlist-t2"},[a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.3280857142857143em"}},[a("span",{staticStyle:{top:"-2.357em","margin-left":"0em","margin-right":"0.07142857142857144em"}},[a("span",{staticClass:"pstrut",staticStyle:{height:"2.5em"}}),a("span",{staticClass:"sizing reset-size3 size1 mtight"},[a("span",{staticClass:"mord mathdefault mtight"},[t._v("i")])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.143em"}},[a("span")])])])])]),a("span",{staticClass:"mclose mtight"},[t._v(")")])])])])]),a("span",{staticClass:"vlist-s"},[t._v("​")])]),a("span",{staticClass:"vlist-r"},[a("span",{staticClass:"vlist",staticStyle:{height:"0.345em"}},[a("span")])])])]),a("span",{staticClass:"mclose nulldelimiter"})])])])])]),t._v(" "),a("p",[t._v("但是使用差分会带来以下问题：")]),t._v(" "),a("ul",[a("li",[t._v("使用较大的ε带来了偏差，而使用较小的ε带来了舍入误差和蒙特卡洛积分的噪声")]),t._v(" "),a("li",[t._v("需要对蒙特卡洛积分进行相关性分析")]),t._v(" "),a("li",[t._v("无法处理众多的场景参数，当有百万级别的场景参数，需要至少对每个参数做一次差分，几乎不太可能用这种方法渲染有百万级别的像素的图像。")])]),t._v(" "),a("p",[a("strong",[t._v("两种基于路径跟踪的GI可微渲染方法介绍")])]),t._v(" "),a("p",[t._v("Differentiable Monte Carlo Ray Tracing through Edge Sampling (Siggraph Asia'18)")]),t._v(" "),a("ul",[a("li",[t._v("使用Reynolds transport theorem把路径积分转换成连续的积分和边界的积分。在不连续的边界上使用边采样来估计积分；")]),t._v(" "),a("li",[t._v("连续的部分仍然使用使用传统的面积采样；")])]),t._v(" "),a("p",[t._v("Reparameterizing Discontinuous Integrands for Differentiable Rendering (Siggraph Asia'19)")]),t._v(" "),a("ul",[a("li",[t._v("对积分进行参数变换, 使得采样过程中不连续的位置不随场景参数变化而变化；")]),t._v(" "),a("li",[t._v("近似导数，对某些场景有较大误差；")]),t._v(" "),a("li",[t._v("集成到了Mitsuba 2中；")])]),t._v(" "),a("h2",{attrs:{id:"不同几何表示的dr"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#不同几何表示的dr"}},[t._v("#")]),t._v(" 不同几何表示的DR")]),t._v(" "),a("p",[t._v("重度参考了这篇文章：\n"),a("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/363358697",target:"_blank",rel:"noopener noreferrer"}},[a("OutboundLink")],1),t._v("\n如果以物体的几何表示角度来看可微渲染，又可以分为如下这些类别：")]),t._v(" "),a("ul",[a("li",[t._v("基于网格的可微渲染（前文基于局部光照模型中提到的两个例子）\n"),a("ul",[a("li",[t._v("OpenDR")]),t._v(" "),a("li",[t._v("SoftRas")])])]),t._v(" "),a("li",[t._v("基于点云的可微渲染\n"),a("ul",[a("li",[t._v("传统方法：\n"),a("ol",[a("li",[t._v("点云做MVP变换")]),t._v(" "),a("li",[t._v("计算每个点的颜色和影响范围")]),t._v(" "),a("li",[t._v("对每个像素，根据点云深度计算像素颜色")])])]),t._v(" "),a("li",[t._v("可微方法：\n"),a("ul",[a("li",[t._v("将点云转化为高斯分布，扩大单个点的影响范围。（类似SoftRas）")])])])])]),t._v(" "),a("li",[t._v("基于体素的可微渲染\n"),a("ul",[a("li",[t._v("传统方法：\n"),a("ol",[a("li",[t._v("确定每根光线经过哪些体素")]),t._v(" "),a("li",[t._v("选取或融合每根光线上体素的信息，得到渲染结果")])])]),t._v(" "),a("li",[t._v("可微方法：\n"),a("ul",[a("li",[t._v("一般只对第二部分进行可微化；")]),t._v(" "),a("li",[t._v("基于隐式表示的可微渲染")])])])])]),t._v(" "),a("li",[t._v("流行的隐式表示：Occupancy field、SDF以及NeRF；\n"),a("ul",[a("li",[t._v("问题相关的，固定点信息的优化；")]),t._v(" "),a("li",[t._v("与体素表示的区别：采样策略")])])])]),t._v(" "),a("h2",{attrs:{id:"神经渲染"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#神经渲染"}},[t._v("#")]),t._v(" 神经渲染")]),t._v(" "),a("p",[t._v("神经渲染并不是一个非常新的领域，很久以前就已经有人在做这方面的研究。但是将神经渲染重新带入大众视野中的论文就不得不提NeRF（ECCV2020 Oral）了。")]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-f32210e94c3e72aa59a31aef4d9b63bf_r.jpg",alt:""}})]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-9088209a67d172d822a703e1ad732126_r.jpg",alt:""}})]),t._v(" "),a("p",[t._v("不知道大家对NeRF的结果有什么感受，反正我第一次见的时候还是非常excited，被震撼到了")]),t._v(" "),a("h3",{attrs:{id:"nerf-neural-radiance-fields，神经辐射场-：用神经网络拟合一个场景的隐式表示"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#nerf-neural-radiance-fields，神经辐射场-：用神经网络拟合一个场景的隐式表示"}},[t._v("#")]),t._v(" NeRF(Neural Radiance Fields，神经辐射场)：用神经网络拟合一个场景的隐式表示")]),t._v(" "),a("p",[t._v("参考了这篇文章：图形学新高潮? NeRF 笔记 - Lee bro的文章 "),a("a",{attrs:{href:"https://zhuanlan.zhihu.com/p/187541908",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://zhuanlan.zhihu.com/p/187541908"),a("OutboundLink")],1)]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-c98908ba5cbfdab311c5b9e586d67f22_r.jpg",alt:""}})]),t._v(" "),a("p",[t._v("NeRF的主要步骤：")]),t._v(" "),a("ol",[a("li",[t._v("沿着相机射线采样5D坐标（位置和View方向）来合成图像")]),t._v(" "),a("li",[t._v("将位置输入到MLP中以产生颜色和体积密度")]),t._v(" "),a("li",[t._v("使用体渲染技术将这些值合成到图像中")]),t._v(" "),a("li",[t._v("根据loss来优化场景表示")])]),t._v(" "),a("p",[t._v("NeRF Details：")]),t._v(" "),a("ul",[a("li",[t._v("透明度α应该和view方向无关，但是rgb和view方向有关, 所以在模型中也force了这个条件, 将view方向(θ,ϕ)作为中间量输入")]),t._v(" "),a("li",[t._v("Input Embedding：将输入映射到高维空间以学习更多细节（见下图）")]),t._v(" "),a("li",[t._v("重要性采样：体渲染时，先做Uniform采样，然后采用重要性采样提高采样质量；")]),t._v(" "),a("li",[t._v("开销:")]),t._v(" "),a("li",[t._v("20~50张输入图片")]),t._v(" "),a("li",[t._v("在NVIDIA V100上需要100sssk~300k次迭代（1~2天）")])]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-c690b349716365b22e46903d776ad610_r.jpg",alt:"Input Embedding示意（source:@Lee bro）"}})]),t._v(" "),a("h3",{attrs:{id:"再谈神经渲染"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#再谈神经渲染"}},[t._v("#")]),t._v(" 再谈神经渲染")]),t._v(" "),a("p",[t._v("起初我对神经渲染的理解比较浅显，觉得就是把渲染器的工作交给神经网络来做，后来看了Siggraph2021 course，以及最近很多的神经渲染相关工作之后，确实觉得自己格局小了。这也是一个相当宽泛的领域。")]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-be0a56aae0a2a5e69b67a6e4548eeda0_r.jpg",alt:"各类神经渲染方法"}})]),t._v(" "),a("p",[t._v("让我们跟随Siggraph2021 Course的思路，以一个high-level的角度去看神经渲染。")]),t._v(" "),a("ol",[a("li",[t._v('"Regress it"')])]),t._v(" "),a("p",[t._v("假设我们把相机位置和朝向编码，输入给一个2D Network，然后这个Network能够生成2D Image，这样我们就实现了从相机参数到图像上像素的一个映射。这个映射可能是非常复杂的，所以训练这个网络需要非常大量的数据。")]),t._v(" "),a("p",[t._v("注意我们训练输入的也只是2D图片，通过训练后，网络能够通过输入的相机参数“脑补”出新视角下的图片。")]),t._v(" "),a("p",[t._v("补充一下GQN：Generative Query Network(GQN)的核心思想是将场景建模为一个可查询的表示，通过查询网络来生成新的视角图像。通过将场景表示与查询过程相结合，GQN能够生成准确且一致的图像，以填补未观察到的视角。")]),t._v(" "),a("p",[t._v("吐槽一句：这篇是DeepMind团队2018年发到Science上的paper，idea确实有点意思，结果渲出来就是一堆像素级别的色块，感觉上就是数据过拟合整出来的，发science有点离谱")]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[t._v('"Make it more real"')])]),t._v(" "),a("p",[t._v("如果我们想少用点训练数据，更泛化一些。这个过程就用到了真正的图形学知识。简而言之就是用3D场景表示和相机数据（or其他场景参数），很正常地丢给传统的渲染器，这时候渲染器生成了一些2D Feature map（可以是深度图，剪影图等等），然后神经网络再通过这些2D Feature map生成最终的2D image。这个就是比较经典的可微神经渲染的方法。")]),t._v(" "),a("ol",{attrs:{start:"3"}},[a("li",[t._v('"Regress & Render"')])]),t._v(" "),a("p",[t._v("这类方法的特点就是，相比2，交换了传统渲染器和神经网络在系统中的位置。首先我们用一些code去描述场景，传递给神经网络后输出了3D场景，然后在用传统渲染器进行渲染正常操作。比如神经体（Nerual Volumes）渲染就是这类方法。")]),t._v(" "),a("ol",{attrs:{start:"4"}},[a("li",[t._v('"Step, sample & blend"')])]),t._v(" "),a("p",[t._v("这类方法有点像拿机器学习和图形学做的三明治，他们作为两种料（组件）被加进了三明治（系统）里，这类方法目前也比较热门，因为效果确实非常stunning。典型的应用NeRF，在前文中已经提到，具体步骤就不再赘述了。")]),t._v(" "),a("p",[t._v("通过一整套了解下来，神经渲染并没有之前理解的那么狭窄。")]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-702ab1aa17653e89fd655b5b7c3e5113_r.jpg",alt:"Siggraph2021Course对神经渲染的定义"}})]),t._v(" "),a("p",[t._v("Siggraph2021Course中，对神经渲染的定义是：用于图像或视频生成的深度神经网络，允许显式或隐式地控制场景属性。")]),t._v(" "),a("ol",[a("li",[t._v("首先我们关注的问题是生成2D像素输出")]),t._v(" "),a("li",[t._v("第二是我们想控制生成哪些图像")]),t._v(" "),a("li",[t._v("第三点是，这个控制是来自于一些物理的参数，相机参数，光照参数，几何的形状等等")])]),t._v(" "),a("h2",{attrs:{id:"可微渲染的前沿应用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#可微渲染的前沿应用"}},[t._v("#")]),t._v(" 可微渲染的前沿应用")]),t._v(" "),a("p",[t._v("文章的最后再插几个我认为比较有意思的可微渲染的前沿Paper")]),t._v(" "),a("h3",{attrs:{id:"parameter-space-restir-for-differentiable-and-inverse-rendering（siggraph-2023"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#parameter-space-restir-for-differentiable-and-inverse-rendering（siggraph-2023"}},[t._v("#")]),t._v(" Parameter-space ReSTIR for Differentiable and Inverse Rendering（Siggraph 2023)")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://www.zhihu.com/video/1657174476067557376",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://www.zhihu.com/video/1657174476067557376"),a("OutboundLink")],1),t._v("\n没想到在除了GI之外的地方又见到了ReSTIR，这篇paper将ReSTIR（蓄水池时空复用重要性重采样）算法用在梯度下降迭代过程中复用样本，论文中列举的应用是优化一张粗糙度贴图，使得使用这张粗糙度贴图的轮胎图像和目标图像尽量相似，实验证明比Mitsuba3收敛要更快。")]),t._v(" "),a("h3",{attrs:{id:"adop-approximate-differentiable-one-pixel-point-rendering（siggraph-2022"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#adop-approximate-differentiable-one-pixel-point-rendering（siggraph-2022"}},[t._v("#")]),t._v(" ADOP: Approximate Differentiable One-Pixel Point Rendering（Siggraph 2022)")]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-495efda577dda823e2ad23a93c4bc6bc_r.jpg",alt:"Overview"}}),t._v(" "),a("a",{attrs:{href:"https://www.zhihu.com/video/1657174370639417345",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://www.zhihu.com/video/1657174370639417345"),a("OutboundLink")],1),t._v("\n输入一些拍摄的图像、带纹理的点云和环境贴图，生成高质量的渲染结果。")]),t._v(" "),a("p",[t._v("管线里包括一个完全可微的基于物理的光度相机（photometric camera）模型，包括了曝光、白平衡和镜头畸变等其他相机参数。通过神经网络学习后，优化所有的结构化输入参数，以提高渲染质量。（效果非常好，github star>1.9k）")]),t._v(" "),a("p",[a("strong",[t._v("解决的问题")]),t._v(" ：")]),t._v(" "),a("ul",[a("li",[t._v("点云空洞填补")]),t._v(" "),a("li",[t._v("自动优化相机参数（曝光、白平衡、畸变等）")]),t._v(" "),a("li",[t._v("高质量实时渲染")])]),t._v(" "),a("p",[a("strong",[t._v("数据规模")]),t._v(" ：")]),t._v(" "),a("ul",[a("li",[t._v("Image:300~800张")]),t._v(" "),a("li",[t._v("Points:~10M")])]),t._v(" "),a("p",[a("strong",[t._v("训练时间")]),t._v(" ：~4h(A100)")]),t._v(" "),a("p",[a("strong",[t._v("推理时间")]),t._v(" ：~27ms(RTX3080)")]),t._v(" "),a("p",[a("strong",[t._v("缺点")]),t._v(" ：")]),t._v(" "),a("ul",[a("li",[t._v("空洞填补比较局限，相机过近或点云稀疏时有闪烁，尤其是相机移动时；")]),t._v(" "),a("li",[t._v("参数太多，超参数不好调，需要先对场景做grid-search")]),t._v(" "),a("li",[t._v("学习率太大时，点位置的优化不稳定，可能是梯度近似导致。")])]),t._v(" "),a("h3",{attrs:{id:"reconstructing-translucent-objects-using-differentiable-rendering-siggraph-2022"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reconstructing-translucent-objects-using-differentiable-rendering-siggraph-2022"}},[t._v("#")]),t._v(" Reconstructing translucent objects using differentiable rendering (Siggraph 2022)")]),t._v(" "),a("p",[t._v("高真实度的半透明材质物体重建")]),t._v(" "),a("ul",[a("li",[t._v("提出一种新方法，针对BSSRDF材质的全局光照可微渲染")]),t._v(" "),a("li",[t._v("对合成半透明物体和基于网格的对象几何的联合重建")]),t._v(" "),a("li",[t._v("对L2 loss的梯度估计的双缓冲解决方案，在低spp情况下快速收敛")])]),t._v(" "),a("p",[a("img",{attrs:{src:"zhimg.com/v2-d9878a9cbb68312343cbeaf046967f76_r.jpg",alt:"全局光照渲染的重建结果，左边三个为合成数据，右边三个为真实数据"}})]),t._v(" "),a("h2",{attrs:{id:"总结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),a("p",[a("strong",[t._v("逆渲染：")])]),t._v(" "),a("ol",[a("li",[a("p",[t._v("渲染的逆过程")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("可微渲染")]),t._v(" 是解决 "),a("strong",[t._v("逆渲染")]),t._v(" 问题的重要方法")])])]),t._v(" "),a("p",[a("strong",[t._v("可微渲染：")])]),t._v(" "),a("ol",[a("li",[a("p",[t._v("一种工具：将三维信息可微地渲染到二维图像，使得二维信息可以对渲染过程做监督；")])]),t._v(" "),a("li",[a("p",[t._v("核心问题：把不可微的渲染步骤变得可微，利用可微渲染进行问题相关的优化；")])]),t._v(" "),a("li",[a("p",[t._v("借助 "),a("strong",[t._v("可微渲染")]),t._v(" ，可以将渲染过程嵌入到更大的优化框架中")])])]),t._v(" "),a("p",[a("strong",[t._v("神经渲染：")])]),t._v(" "),a("ol",[a("li",[a("strong",[t._v("神经渲染：")])])]),t._v(" "),a("ul",[a("li",[t._v("sig course的定义：用于图像或视频生成的深度神经网络，允许显式或隐式地控制场景属性；")]),t._v(" "),a("li",[t._v("我个人目前的理解：在类似传统渲染，生成二维图像的过程中，使用了神经网络完成了其中一部分甚至全部的工作；")])]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[a("p",[t._v("让神经网络学习场景表示、feature map到渲染结果image等过程；")])]),t._v(" "),a("li",[a("p",[a("strong",[t._v("可微渲染")]),t._v(" 可以用于优化 "),a("strong",[t._v("神经渲染")]),t._v(" 的过程；")])])]),t._v(" "),a("p",[t._v("P.S. 很推荐有CG基础想了解可微渲染的朋友读一下参考资料1的论文，清华大学写的一篇关于可微渲染的综述，讲得很全面。知乎上有好几篇文章其实都是基于它来写的（包括我这篇）")]),t._v(" "),a("p",[t._v("如果对神经渲染感兴趣的朋友可以看一下参考资料4里的Siggraph Course，本身就在做这些topic的大牛对问题看得更透彻一些，几个油管链接b站基本都能找到对应的搬运视频。")]),t._v(" "),a("h2",{attrs:{id:"参考资料"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考资料"}},[t._v("#")]),t._v(" 参考资料")]),t._v(" "),a("ol",[a("li",[t._v("叶子鹏,夏雯宇,孙志尧,易冉,余旻婧,刘永进.从传统渲染到可微渲染:基本原理、方法和应用[J].中国科学:信息科学,2021,51(07):1043-1067.")]),t._v(" "),a("li",[t._v("Physics-based differentiable rendering (CVPR 2021 tutorial) "),a("a",{attrs:{href:"https://youtu.be/Tou8or1ed6E",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://youtu.be/Tou8or1ed6E"),a("OutboundLink")],1)]),t._v(" "),a("li",[t._v("MIT 6.S191 (2020): Neural Rendering "),a("a",{attrs:{href:"https://youtu.be/BCZ56MU-KhQ",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://youtu.be/BCZ56MU-KhQ"),a("OutboundLink")],1)]),t._v(" "),a("li",[t._v("Advances in Neural Rendering (SIGGRAPH 2021 Course) "),a("a",{attrs:{href:"https://youtu.be/otly9jcZ0Jg",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://youtu.be/otly9jcZ0Jg"),a("OutboundLink")],1)]),t._v(" "),a("li",[t._v("Neural Rendering (CVPR 2020) - Morning Session "),a("a",{attrs:{href:"https://youtu.be/LCTYRqW-ne8",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://youtu.be/LCTYRqW-ne8"),a("OutboundLink")],1)])])])}),[],!1,null,null,null);s.default=e.exports}}]);