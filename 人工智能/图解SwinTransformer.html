<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>【纯转载】图解Swin Transformer | Yin的笔记本</title>
    <meta name="generator" content="VuePress 1.5.0">
    <link rel="icon" href="/favicon.ico">
    <link rel="stylesheet" href="https://fastly.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">
    <link rel="stylesheet" href="https://fastly.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css">
    <meta name="description" content="Yin的笔记本">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    <link rel="preload" href="/assets/css/0.styles.2d94763a.css" as="style"><link rel="preload" href="/assets/js/app.1c89d7eb.js" as="script"><link rel="preload" href="/assets/js/3.63b8c0eb.js" as="script"><link rel="preload" href="/assets/js/1.be3d2055.js" as="script"><link rel="preload" href="/assets/js/154.60508725.js" as="script"><link rel="prefetch" href="/assets/js/10.7997888a.js"><link rel="prefetch" href="/assets/js/100.2278e289.js"><link rel="prefetch" href="/assets/js/101.12c66a26.js"><link rel="prefetch" href="/assets/js/102.6468aee3.js"><link rel="prefetch" href="/assets/js/103.d1dd7048.js"><link rel="prefetch" href="/assets/js/104.f4890013.js"><link rel="prefetch" href="/assets/js/105.a97deef5.js"><link rel="prefetch" href="/assets/js/106.c1bcc835.js"><link rel="prefetch" href="/assets/js/107.03ab02e9.js"><link rel="prefetch" href="/assets/js/108.ce9a9508.js"><link rel="prefetch" href="/assets/js/109.d03fd13e.js"><link rel="prefetch" href="/assets/js/11.f5bd6d01.js"><link rel="prefetch" href="/assets/js/110.13c311a4.js"><link rel="prefetch" href="/assets/js/111.6f30518f.js"><link rel="prefetch" href="/assets/js/112.ca951fb9.js"><link rel="prefetch" href="/assets/js/113.9c5c0582.js"><link rel="prefetch" href="/assets/js/114.eb24eb1a.js"><link rel="prefetch" href="/assets/js/115.de265fa2.js"><link rel="prefetch" href="/assets/js/116.24745fa4.js"><link rel="prefetch" href="/assets/js/117.86d4e841.js"><link rel="prefetch" href="/assets/js/118.9dbd6211.js"><link rel="prefetch" href="/assets/js/119.d8ec6ee3.js"><link rel="prefetch" href="/assets/js/12.770bcdd1.js"><link rel="prefetch" href="/assets/js/120.21b9b7e4.js"><link rel="prefetch" href="/assets/js/121.69c915c7.js"><link rel="prefetch" href="/assets/js/122.ddedddba.js"><link rel="prefetch" href="/assets/js/123.5a80347b.js"><link rel="prefetch" href="/assets/js/124.71bff2da.js"><link rel="prefetch" href="/assets/js/125.21830b23.js"><link rel="prefetch" href="/assets/js/126.f30185cf.js"><link rel="prefetch" href="/assets/js/127.3aeb1f53.js"><link rel="prefetch" href="/assets/js/128.6c296bf9.js"><link rel="prefetch" href="/assets/js/129.fda4528b.js"><link rel="prefetch" href="/assets/js/13.070330f5.js"><link rel="prefetch" href="/assets/js/130.9e6b67b0.js"><link rel="prefetch" href="/assets/js/131.20b0e822.js"><link rel="prefetch" href="/assets/js/132.a35815d1.js"><link rel="prefetch" href="/assets/js/133.bfa0daa0.js"><link rel="prefetch" href="/assets/js/134.eaea7aba.js"><link rel="prefetch" href="/assets/js/135.3a5c98a8.js"><link rel="prefetch" href="/assets/js/136.01223e0d.js"><link rel="prefetch" href="/assets/js/137.7cce857f.js"><link rel="prefetch" href="/assets/js/138.7a586d88.js"><link rel="prefetch" href="/assets/js/139.3f8891f1.js"><link rel="prefetch" href="/assets/js/14.760d4ae9.js"><link rel="prefetch" href="/assets/js/140.7d36bb0c.js"><link rel="prefetch" href="/assets/js/141.b2a3eaa6.js"><link rel="prefetch" href="/assets/js/142.8765938e.js"><link rel="prefetch" href="/assets/js/143.877037ca.js"><link rel="prefetch" href="/assets/js/144.0c63859f.js"><link rel="prefetch" href="/assets/js/145.0826322f.js"><link rel="prefetch" href="/assets/js/146.0c7793ea.js"><link rel="prefetch" href="/assets/js/147.208c0c3d.js"><link rel="prefetch" href="/assets/js/148.e7e56ea0.js"><link rel="prefetch" href="/assets/js/149.269f672b.js"><link rel="prefetch" href="/assets/js/15.6dd745f8.js"><link rel="prefetch" href="/assets/js/150.5b335113.js"><link rel="prefetch" href="/assets/js/151.98e0c301.js"><link rel="prefetch" href="/assets/js/152.b8f48d96.js"><link rel="prefetch" href="/assets/js/153.bfeb3233.js"><link rel="prefetch" href="/assets/js/155.b8a1e762.js"><link rel="prefetch" href="/assets/js/156.a002dc45.js"><link rel="prefetch" href="/assets/js/157.5e547455.js"><link rel="prefetch" href="/assets/js/158.d2f2e77b.js"><link rel="prefetch" href="/assets/js/159.200ec9a4.js"><link rel="prefetch" href="/assets/js/16.6860f890.js"><link rel="prefetch" href="/assets/js/160.c842c71c.js"><link rel="prefetch" href="/assets/js/161.b69b41de.js"><link rel="prefetch" href="/assets/js/162.abaa0820.js"><link rel="prefetch" href="/assets/js/163.781d45a1.js"><link rel="prefetch" href="/assets/js/164.489c9172.js"><link rel="prefetch" href="/assets/js/165.4001e6a3.js"><link rel="prefetch" href="/assets/js/166.f605c3b7.js"><link rel="prefetch" href="/assets/js/167.187f7fef.js"><link rel="prefetch" href="/assets/js/168.8e751948.js"><link rel="prefetch" href="/assets/js/169.5c50b84f.js"><link rel="prefetch" href="/assets/js/17.96a61fae.js"><link rel="prefetch" href="/assets/js/170.c145b06c.js"><link rel="prefetch" href="/assets/js/171.1ff621e6.js"><link rel="prefetch" href="/assets/js/172.b5012bca.js"><link rel="prefetch" href="/assets/js/173.5bfa26a7.js"><link rel="prefetch" href="/assets/js/174.09fa2f55.js"><link rel="prefetch" href="/assets/js/175.d9227914.js"><link rel="prefetch" href="/assets/js/176.00adae9b.js"><link rel="prefetch" href="/assets/js/177.919b9f47.js"><link rel="prefetch" href="/assets/js/178.7e815bb2.js"><link rel="prefetch" href="/assets/js/179.7abd2d00.js"><link rel="prefetch" href="/assets/js/18.e9d7c71b.js"><link rel="prefetch" href="/assets/js/180.655d5d4a.js"><link rel="prefetch" href="/assets/js/181.b46b1de0.js"><link rel="prefetch" href="/assets/js/182.2e8f1a2a.js"><link rel="prefetch" href="/assets/js/183.22265de0.js"><link rel="prefetch" href="/assets/js/184.74507e51.js"><link rel="prefetch" href="/assets/js/185.bfa1144d.js"><link rel="prefetch" href="/assets/js/186.823452a1.js"><link rel="prefetch" href="/assets/js/187.4d75455f.js"><link rel="prefetch" href="/assets/js/188.916ab9d4.js"><link rel="prefetch" href="/assets/js/189.add9f2bf.js"><link rel="prefetch" href="/assets/js/19.f46a344f.js"><link rel="prefetch" href="/assets/js/190.193af7ee.js"><link rel="prefetch" href="/assets/js/191.30e19787.js"><link rel="prefetch" href="/assets/js/192.485b0912.js"><link rel="prefetch" href="/assets/js/193.ec31135d.js"><link rel="prefetch" href="/assets/js/194.b6f1ea36.js"><link rel="prefetch" href="/assets/js/195.f41818b6.js"><link rel="prefetch" href="/assets/js/196.3997fb55.js"><link rel="prefetch" href="/assets/js/197.9316466e.js"><link rel="prefetch" href="/assets/js/198.d6eaf8d5.js"><link rel="prefetch" href="/assets/js/199.7833a5cf.js"><link rel="prefetch" href="/assets/js/20.3e59b7db.js"><link rel="prefetch" href="/assets/js/200.09ac4b4c.js"><link rel="prefetch" href="/assets/js/201.c181d266.js"><link rel="prefetch" href="/assets/js/202.0c17f434.js"><link rel="prefetch" href="/assets/js/203.f325f13a.js"><link rel="prefetch" href="/assets/js/204.cc6ab889.js"><link rel="prefetch" href="/assets/js/205.5dea103e.js"><link rel="prefetch" href="/assets/js/206.d4bed4f0.js"><link rel="prefetch" href="/assets/js/207.570e9c30.js"><link rel="prefetch" href="/assets/js/208.15c57dde.js"><link rel="prefetch" href="/assets/js/209.052fb626.js"><link rel="prefetch" href="/assets/js/21.0d860ace.js"><link rel="prefetch" href="/assets/js/210.17da69e7.js"><link rel="prefetch" href="/assets/js/211.0437b47a.js"><link rel="prefetch" href="/assets/js/212.6d3516a5.js"><link rel="prefetch" href="/assets/js/213.2016ed1e.js"><link rel="prefetch" href="/assets/js/214.8d375069.js"><link rel="prefetch" href="/assets/js/215.6895df63.js"><link rel="prefetch" href="/assets/js/216.c044b620.js"><link rel="prefetch" href="/assets/js/217.1ff7a370.js"><link rel="prefetch" href="/assets/js/218.2b5c6610.js"><link rel="prefetch" href="/assets/js/219.3d1b7c68.js"><link rel="prefetch" href="/assets/js/22.395f0662.js"><link rel="prefetch" href="/assets/js/220.2f7d0eb4.js"><link rel="prefetch" href="/assets/js/221.0d5c483a.js"><link rel="prefetch" href="/assets/js/222.b4e8edd9.js"><link rel="prefetch" href="/assets/js/223.ed8cd7c5.js"><link rel="prefetch" href="/assets/js/224.70f8536d.js"><link rel="prefetch" href="/assets/js/225.877f00f4.js"><link rel="prefetch" href="/assets/js/226.e6433587.js"><link rel="prefetch" href="/assets/js/227.57bea06d.js"><link rel="prefetch" href="/assets/js/228.46f056e8.js"><link rel="prefetch" href="/assets/js/229.e075c130.js"><link rel="prefetch" href="/assets/js/23.918096ae.js"><link rel="prefetch" href="/assets/js/230.513baab1.js"><link rel="prefetch" href="/assets/js/231.107ef86e.js"><link rel="prefetch" href="/assets/js/232.498787e8.js"><link rel="prefetch" href="/assets/js/233.c9c37e3d.js"><link rel="prefetch" href="/assets/js/234.3205c614.js"><link rel="prefetch" href="/assets/js/235.6e73d096.js"><link rel="prefetch" href="/assets/js/236.1cd1beda.js"><link rel="prefetch" href="/assets/js/237.4708c31e.js"><link rel="prefetch" href="/assets/js/238.8e5fe2c7.js"><link rel="prefetch" href="/assets/js/239.d6960886.js"><link rel="prefetch" href="/assets/js/24.191c578f.js"><link rel="prefetch" href="/assets/js/240.ac10844d.js"><link rel="prefetch" href="/assets/js/241.d176cd12.js"><link rel="prefetch" href="/assets/js/242.05602258.js"><link rel="prefetch" href="/assets/js/243.04d4eea2.js"><link rel="prefetch" href="/assets/js/244.666552a4.js"><link rel="prefetch" href="/assets/js/245.391a0ebb.js"><link rel="prefetch" href="/assets/js/246.bbc73f23.js"><link rel="prefetch" href="/assets/js/247.2fb1308f.js"><link rel="prefetch" href="/assets/js/248.cb32facb.js"><link rel="prefetch" href="/assets/js/249.8f2c20c3.js"><link rel="prefetch" href="/assets/js/25.9fa7a0f1.js"><link rel="prefetch" href="/assets/js/250.aee82d40.js"><link rel="prefetch" href="/assets/js/251.b27f9949.js"><link rel="prefetch" href="/assets/js/252.0d3a1c08.js"><link rel="prefetch" href="/assets/js/253.dbac77db.js"><link rel="prefetch" href="/assets/js/254.daeb0894.js"><link rel="prefetch" href="/assets/js/255.9ae341b8.js"><link rel="prefetch" href="/assets/js/256.0914df92.js"><link rel="prefetch" href="/assets/js/257.17692151.js"><link rel="prefetch" href="/assets/js/258.6a51affa.js"><link rel="prefetch" href="/assets/js/259.cfa1b7e2.js"><link rel="prefetch" href="/assets/js/26.977b91ed.js"><link rel="prefetch" href="/assets/js/260.01a0a834.js"><link rel="prefetch" href="/assets/js/261.7c6786a8.js"><link rel="prefetch" href="/assets/js/262.40aa6ec8.js"><link rel="prefetch" href="/assets/js/263.9b768341.js"><link rel="prefetch" href="/assets/js/264.3516b6ee.js"><link rel="prefetch" href="/assets/js/265.24ebac38.js"><link rel="prefetch" href="/assets/js/266.d0f18960.js"><link rel="prefetch" href="/assets/js/267.cb67bfa7.js"><link rel="prefetch" href="/assets/js/268.49a739ea.js"><link rel="prefetch" href="/assets/js/269.319f9495.js"><link rel="prefetch" href="/assets/js/27.cbf02bc2.js"><link rel="prefetch" href="/assets/js/270.0ab89f8c.js"><link rel="prefetch" href="/assets/js/271.5ebfdaad.js"><link rel="prefetch" href="/assets/js/272.d978c09e.js"><link rel="prefetch" href="/assets/js/273.c2ca9559.js"><link rel="prefetch" href="/assets/js/274.ef3c0b4e.js"><link rel="prefetch" href="/assets/js/275.0cb280a9.js"><link rel="prefetch" href="/assets/js/276.f01bb24d.js"><link rel="prefetch" href="/assets/js/277.4336236b.js"><link rel="prefetch" href="/assets/js/278.91b80a10.js"><link rel="prefetch" href="/assets/js/279.a3dba48a.js"><link rel="prefetch" href="/assets/js/28.ea6f85eb.js"><link rel="prefetch" href="/assets/js/280.28c7e56d.js"><link rel="prefetch" href="/assets/js/281.b40bcb2f.js"><link rel="prefetch" href="/assets/js/282.8b95f9c1.js"><link rel="prefetch" href="/assets/js/283.112bae13.js"><link rel="prefetch" href="/assets/js/284.32679d92.js"><link rel="prefetch" href="/assets/js/285.5d940ba6.js"><link rel="prefetch" href="/assets/js/286.7644400d.js"><link rel="prefetch" href="/assets/js/287.3e55ea4a.js"><link rel="prefetch" href="/assets/js/288.e008719f.js"><link rel="prefetch" href="/assets/js/289.288c8559.js"><link rel="prefetch" href="/assets/js/29.09e2943e.js"><link rel="prefetch" href="/assets/js/290.5e886e4a.js"><link rel="prefetch" href="/assets/js/291.317a7f21.js"><link rel="prefetch" href="/assets/js/292.8e9221de.js"><link rel="prefetch" href="/assets/js/293.d2e72c3b.js"><link rel="prefetch" href="/assets/js/294.b08bb0a5.js"><link rel="prefetch" href="/assets/js/295.0ff3e8b8.js"><link rel="prefetch" href="/assets/js/296.8db2437f.js"><link rel="prefetch" href="/assets/js/297.df969d5b.js"><link rel="prefetch" href="/assets/js/298.5e04335e.js"><link rel="prefetch" href="/assets/js/299.30af4295.js"><link rel="prefetch" href="/assets/js/30.8ce7bb1c.js"><link rel="prefetch" href="/assets/js/300.bbee17de.js"><link rel="prefetch" href="/assets/js/301.658e30a9.js"><link rel="prefetch" href="/assets/js/302.83a48594.js"><link rel="prefetch" href="/assets/js/303.25b5c5d0.js"><link rel="prefetch" href="/assets/js/304.d1cda2a7.js"><link rel="prefetch" href="/assets/js/305.ec45274c.js"><link rel="prefetch" href="/assets/js/306.f5481c32.js"><link rel="prefetch" href="/assets/js/307.477c6cfe.js"><link rel="prefetch" href="/assets/js/308.2fc60e29.js"><link rel="prefetch" href="/assets/js/309.d3153724.js"><link rel="prefetch" href="/assets/js/31.9a171aa4.js"><link rel="prefetch" href="/assets/js/310.cd447685.js"><link rel="prefetch" href="/assets/js/311.aa55b174.js"><link rel="prefetch" href="/assets/js/312.975cb9f5.js"><link rel="prefetch" href="/assets/js/313.ff1ed35d.js"><link rel="prefetch" href="/assets/js/314.0f909559.js"><link rel="prefetch" href="/assets/js/315.db32db01.js"><link rel="prefetch" href="/assets/js/32.947f503d.js"><link rel="prefetch" href="/assets/js/33.59e6f3ca.js"><link rel="prefetch" href="/assets/js/34.d611cc6b.js"><link rel="prefetch" href="/assets/js/35.1bcf17ab.js"><link rel="prefetch" href="/assets/js/36.4ce4f82a.js"><link rel="prefetch" href="/assets/js/37.0054f8c4.js"><link rel="prefetch" href="/assets/js/38.b4bdef00.js"><link rel="prefetch" href="/assets/js/39.436a4cf2.js"><link rel="prefetch" href="/assets/js/4.71970d79.js"><link rel="prefetch" href="/assets/js/40.3c0f9211.js"><link rel="prefetch" href="/assets/js/41.db84a37b.js"><link rel="prefetch" href="/assets/js/42.d490b527.js"><link rel="prefetch" href="/assets/js/43.53ff8034.js"><link rel="prefetch" href="/assets/js/44.6ac3003e.js"><link rel="prefetch" href="/assets/js/45.c5e657d2.js"><link rel="prefetch" href="/assets/js/46.9c37bbc9.js"><link rel="prefetch" href="/assets/js/47.8cc0235f.js"><link rel="prefetch" href="/assets/js/48.46917f1a.js"><link rel="prefetch" href="/assets/js/49.4956c196.js"><link rel="prefetch" href="/assets/js/5.b5c477bb.js"><link rel="prefetch" href="/assets/js/50.c350ef1e.js"><link rel="prefetch" href="/assets/js/51.228f9fb4.js"><link rel="prefetch" href="/assets/js/52.d0ea8325.js"><link rel="prefetch" href="/assets/js/53.bcf8531d.js"><link rel="prefetch" href="/assets/js/54.823cdd86.js"><link rel="prefetch" href="/assets/js/55.dd739e97.js"><link rel="prefetch" href="/assets/js/56.0a6fa41e.js"><link rel="prefetch" href="/assets/js/57.e8c7ac20.js"><link rel="prefetch" href="/assets/js/58.9a6ccc24.js"><link rel="prefetch" href="/assets/js/59.a3e64ba9.js"><link rel="prefetch" href="/assets/js/6.8d75c7c7.js"><link rel="prefetch" href="/assets/js/60.4ef57d04.js"><link rel="prefetch" href="/assets/js/61.b2221af0.js"><link rel="prefetch" href="/assets/js/62.d5e651a6.js"><link rel="prefetch" href="/assets/js/63.7cf7bbf5.js"><link rel="prefetch" href="/assets/js/64.a1b2ab5f.js"><link rel="prefetch" href="/assets/js/65.795f8ce1.js"><link rel="prefetch" href="/assets/js/66.766bae3c.js"><link rel="prefetch" href="/assets/js/67.33fffa58.js"><link rel="prefetch" href="/assets/js/68.34cad213.js"><link rel="prefetch" href="/assets/js/69.44ab1539.js"><link rel="prefetch" href="/assets/js/7.c826a528.js"><link rel="prefetch" href="/assets/js/70.0b157f44.js"><link rel="prefetch" href="/assets/js/71.dda3257f.js"><link rel="prefetch" href="/assets/js/72.e4fd59e4.js"><link rel="prefetch" href="/assets/js/73.5bfac475.js"><link rel="prefetch" href="/assets/js/74.106dce7c.js"><link rel="prefetch" href="/assets/js/75.febe432a.js"><link rel="prefetch" href="/assets/js/76.9d7b680c.js"><link rel="prefetch" href="/assets/js/77.53d02bdd.js"><link rel="prefetch" href="/assets/js/78.78f8bd3e.js"><link rel="prefetch" href="/assets/js/79.765020db.js"><link rel="prefetch" href="/assets/js/8.94c271b3.js"><link rel="prefetch" href="/assets/js/80.58708562.js"><link rel="prefetch" href="/assets/js/81.b496be82.js"><link rel="prefetch" href="/assets/js/82.e7fb031b.js"><link rel="prefetch" href="/assets/js/83.9a97b3c4.js"><link rel="prefetch" href="/assets/js/84.46388e53.js"><link rel="prefetch" href="/assets/js/85.273a246a.js"><link rel="prefetch" href="/assets/js/86.0f1a102d.js"><link rel="prefetch" href="/assets/js/87.0340887c.js"><link rel="prefetch" href="/assets/js/88.2464434e.js"><link rel="prefetch" href="/assets/js/89.9c7259c6.js"><link rel="prefetch" href="/assets/js/9.13823324.js"><link rel="prefetch" href="/assets/js/90.fc961b8c.js"><link rel="prefetch" href="/assets/js/91.05ce823e.js"><link rel="prefetch" href="/assets/js/92.6f598c32.js"><link rel="prefetch" href="/assets/js/93.9b4a4e9b.js"><link rel="prefetch" href="/assets/js/94.e181fada.js"><link rel="prefetch" href="/assets/js/95.1f019ce8.js"><link rel="prefetch" href="/assets/js/96.c5fdf710.js"><link rel="prefetch" href="/assets/js/97.64f5f96a.js"><link rel="prefetch" href="/assets/js/98.e761ab9f.js"><link rel="prefetch" href="/assets/js/99.b19b68c9.js">
    <link rel="stylesheet" href="/assets/css/0.styles.2d94763a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-42dd5e05><div data-v-42dd5e05><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-42dd5e05 data-v-42dd5e05><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-95c9a4e8 data-v-42dd5e05 data-v-42dd5e05><h3 class="title" style="display:none;" data-v-95c9a4e8 data-v-95c9a4e8>Yin的笔记本</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-95c9a4e8 data-v-95c9a4e8><input type="password" value="" data-v-95c9a4e8> <span data-v-95c9a4e8>Konck! Knock!</span> <button data-v-95c9a4e8>OK</button></label> <div class="footer" style="display:none;" data-v-95c9a4e8 data-v-95c9a4e8><span data-v-95c9a4e8><i class="iconfont reco-theme" data-v-95c9a4e8></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-95c9a4e8>vuePress-theme-reco</a></span> <span data-v-95c9a4e8><i class="iconfont reco-copyright" data-v-95c9a4e8></i> <a data-v-95c9a4e8><span data-v-95c9a4e8>Howard Yin</span>
            
          <span data-v-95c9a4e8>2021 - </span>
          2025
        </a></span></div></div> <div class="hide" data-v-42dd5e05><header class="navbar" data-v-42dd5e05><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/logo.png" alt="Yin的笔记本" class="logo"> <span class="site-name">Yin的笔记本</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/CNCF/" class="nav-link"><i class="iconfont undefined"></i>
  CNCF
</a></li><li class="dropdown-item"><!----> <a href="/categories/Docker/" class="nav-link"><i class="iconfont undefined"></i>
  Docker
</a></li><li class="dropdown-item"><!----> <a href="/categories/namespaces/" class="nav-link"><i class="iconfont undefined"></i>
  namespaces
</a></li><li class="dropdown-item"><!----> <a href="/categories/Kubernetes/" class="nav-link"><i class="iconfont undefined"></i>
  Kubernetes
</a></li><li class="dropdown-item"><!----> <a href="/categories/Kubernetes对象/" class="nav-link"><i class="iconfont undefined"></i>
  Kubernetes对象
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="iconfont undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/MyIdeas/" class="nav-link"><i class="iconfont undefined"></i>
  MyIdeas
</a></li><li class="dropdown-item"><!----> <a href="/categories/Revolution/" class="nav-link"><i class="iconfont undefined"></i>
  Revolution
</a></li><li class="dropdown-item"><!----> <a href="/categories/WebRTC/" class="nav-link"><i class="iconfont undefined"></i>
  WebRTC
</a></li><li class="dropdown-item"><!----> <a href="/categories/云计算/" class="nav-link"><i class="iconfont undefined"></i>
  云计算
</a></li><li class="dropdown-item"><!----> <a href="/categories/人工智能/" class="nav-link"><i class="iconfont undefined"></i>
  人工智能
</a></li><li class="dropdown-item"><!----> <a href="/categories/分布式/" class="nav-link"><i class="iconfont undefined"></i>
  分布式
</a></li><li class="dropdown-item"><!----> <a href="/categories/图像处理/" class="nav-link"><i class="iconfont undefined"></i>
  图像处理
</a></li><li class="dropdown-item"><!----> <a href="/categories/图形学/" class="nav-link"><i class="iconfont undefined"></i>
  图形学
</a></li><li class="dropdown-item"><!----> <a href="/categories/微服务/" class="nav-link"><i class="iconfont undefined"></i>
  微服务
</a></li><li class="dropdown-item"><!----> <a href="/categories/数学/" class="nav-link"><i class="iconfont undefined"></i>
  数学
</a></li><li class="dropdown-item"><!----> <a href="/categories/OJ笔记/" class="nav-link"><i class="iconfont undefined"></i>
  OJ笔记
</a></li><li class="dropdown-item"><!----> <a href="/categories/博弈论/" class="nav-link"><i class="iconfont undefined"></i>
  博弈论
</a></li><li class="dropdown-item"><!----> <a href="/categories/形式语言与自动机/" class="nav-link"><i class="iconfont undefined"></i>
  形式语言与自动机
</a></li><li class="dropdown-item"><!----> <a href="/categories/数据库/" class="nav-link"><i class="iconfont undefined"></i>
  数据库
</a></li><li class="dropdown-item"><!----> <a href="/categories/服务器运维/" class="nav-link"><i class="iconfont undefined"></i>
  服务器运维
</a></li><li class="dropdown-item"><!----> <a href="/categories/编程语言/" class="nav-link"><i class="iconfont undefined"></i>
  编程语言
</a></li><li class="dropdown-item"><!----> <a href="/categories/C/" class="nav-link"><i class="iconfont undefined"></i>
  C
</a></li><li class="dropdown-item"><!----> <a href="/categories/Git/" class="nav-link"><i class="iconfont undefined"></i>
  Git
</a></li><li class="dropdown-item"><!----> <a href="/categories/Go/" class="nav-link"><i class="iconfont undefined"></i>
  Go
</a></li><li class="dropdown-item"><!----> <a href="/categories/Java/" class="nav-link"><i class="iconfont undefined"></i>
  Java
</a></li><li class="dropdown-item"><!----> <a href="/categories/JavaScript/" class="nav-link"><i class="iconfont undefined"></i>
  JavaScript
</a></li><li class="dropdown-item"><!----> <a href="/categories/Python/" class="nav-link"><i class="iconfont undefined"></i>
  Python
</a></li><li class="dropdown-item"><!----> <a href="/categories/Nvidia/" class="nav-link"><i class="iconfont undefined"></i>
  Nvidia
</a></li><li class="dropdown-item"><!----> <a href="/categories/Shell/" class="nav-link"><i class="iconfont undefined"></i>
  Shell
</a></li><li class="dropdown-item"><!----> <a href="/categories/Tex/" class="nav-link"><i class="iconfont undefined"></i>
  Tex
</a></li><li class="dropdown-item"><!----> <a href="/categories/Rust/" class="nav-link"><i class="iconfont undefined"></i>
  Rust
</a></li><li class="dropdown-item"><!----> <a href="/categories/Vue/" class="nav-link"><i class="iconfont undefined"></i>
  Vue
</a></li><li class="dropdown-item"><!----> <a href="/categories/视频编解码/" class="nav-link"><i class="iconfont undefined"></i>
  视频编解码
</a></li><li class="dropdown-item"><!----> <a href="/categories/计算机网络/" class="nav-link"><i class="iconfont undefined"></i>
  计算机网络
</a></li><li class="dropdown-item"><!----> <a href="/categories/SDN/" class="nav-link"><i class="iconfont undefined"></i>
  SDN
</a></li><li class="dropdown-item"><!----> <a href="/categories/论文笔记/" class="nav-link"><i class="iconfont undefined"></i>
  论文笔记
</a></li><li class="dropdown-item"><!----> <a href="/categories/讨论/" class="nav-link"><i class="iconfont undefined"></i>
  讨论
</a></li><li class="dropdown-item"><!----> <a href="/categories/边缘计算/" class="nav-link"><i class="iconfont undefined"></i>
  边缘计算
</a></li><li class="dropdown-item"><!----> <a href="/categories/量子信息技术/" class="nav-link"><i class="iconfont undefined"></i>
  量子信息技术
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><a href="http://profile.yindaheng98.top" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-account"></i>
  About
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <a href="https://github.com/yindaheng98/Notebook/tree/master/学习笔记" target="_blank" rel="noopener noreferrer" class="repo-link"><i class="iconfont reco-查看源码"></i>
    查看源码
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask" data-v-42dd5e05></div> <aside class="sidebar" data-v-42dd5e05><div class="personal-info-wrapper" data-v-0ac41e2e><img src="/avatar.svg" alt="author-avatar" class="personal-img" data-v-0ac41e2e> <h3 class="name" data-v-0ac41e2e>
    Howard Yin
  </h3> <div class="num" data-v-0ac41e2e><div data-v-0ac41e2e><h3 data-v-0ac41e2e>304</h3> <h6 data-v-0ac41e2e>Article</h6></div> <div data-v-0ac41e2e><h3 data-v-0ac41e2e>153</h3> <h6 data-v-0ac41e2e>Tag</h6></div></div> <hr data-v-0ac41e2e></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/CNCF/" class="nav-link"><i class="iconfont undefined"></i>
  CNCF
</a></li><li class="dropdown-item"><!----> <a href="/categories/Docker/" class="nav-link"><i class="iconfont undefined"></i>
  Docker
</a></li><li class="dropdown-item"><!----> <a href="/categories/namespaces/" class="nav-link"><i class="iconfont undefined"></i>
  namespaces
</a></li><li class="dropdown-item"><!----> <a href="/categories/Kubernetes/" class="nav-link"><i class="iconfont undefined"></i>
  Kubernetes
</a></li><li class="dropdown-item"><!----> <a href="/categories/Kubernetes对象/" class="nav-link"><i class="iconfont undefined"></i>
  Kubernetes对象
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="iconfont undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/MyIdeas/" class="nav-link"><i class="iconfont undefined"></i>
  MyIdeas
</a></li><li class="dropdown-item"><!----> <a href="/categories/Revolution/" class="nav-link"><i class="iconfont undefined"></i>
  Revolution
</a></li><li class="dropdown-item"><!----> <a href="/categories/WebRTC/" class="nav-link"><i class="iconfont undefined"></i>
  WebRTC
</a></li><li class="dropdown-item"><!----> <a href="/categories/云计算/" class="nav-link"><i class="iconfont undefined"></i>
  云计算
</a></li><li class="dropdown-item"><!----> <a href="/categories/人工智能/" class="nav-link"><i class="iconfont undefined"></i>
  人工智能
</a></li><li class="dropdown-item"><!----> <a href="/categories/分布式/" class="nav-link"><i class="iconfont undefined"></i>
  分布式
</a></li><li class="dropdown-item"><!----> <a href="/categories/图像处理/" class="nav-link"><i class="iconfont undefined"></i>
  图像处理
</a></li><li class="dropdown-item"><!----> <a href="/categories/图形学/" class="nav-link"><i class="iconfont undefined"></i>
  图形学
</a></li><li class="dropdown-item"><!----> <a href="/categories/微服务/" class="nav-link"><i class="iconfont undefined"></i>
  微服务
</a></li><li class="dropdown-item"><!----> <a href="/categories/数学/" class="nav-link"><i class="iconfont undefined"></i>
  数学
</a></li><li class="dropdown-item"><!----> <a href="/categories/OJ笔记/" class="nav-link"><i class="iconfont undefined"></i>
  OJ笔记
</a></li><li class="dropdown-item"><!----> <a href="/categories/博弈论/" class="nav-link"><i class="iconfont undefined"></i>
  博弈论
</a></li><li class="dropdown-item"><!----> <a href="/categories/形式语言与自动机/" class="nav-link"><i class="iconfont undefined"></i>
  形式语言与自动机
</a></li><li class="dropdown-item"><!----> <a href="/categories/数据库/" class="nav-link"><i class="iconfont undefined"></i>
  数据库
</a></li><li class="dropdown-item"><!----> <a href="/categories/服务器运维/" class="nav-link"><i class="iconfont undefined"></i>
  服务器运维
</a></li><li class="dropdown-item"><!----> <a href="/categories/编程语言/" class="nav-link"><i class="iconfont undefined"></i>
  编程语言
</a></li><li class="dropdown-item"><!----> <a href="/categories/C/" class="nav-link"><i class="iconfont undefined"></i>
  C
</a></li><li class="dropdown-item"><!----> <a href="/categories/Git/" class="nav-link"><i class="iconfont undefined"></i>
  Git
</a></li><li class="dropdown-item"><!----> <a href="/categories/Go/" class="nav-link"><i class="iconfont undefined"></i>
  Go
</a></li><li class="dropdown-item"><!----> <a href="/categories/Java/" class="nav-link"><i class="iconfont undefined"></i>
  Java
</a></li><li class="dropdown-item"><!----> <a href="/categories/JavaScript/" class="nav-link"><i class="iconfont undefined"></i>
  JavaScript
</a></li><li class="dropdown-item"><!----> <a href="/categories/Python/" class="nav-link"><i class="iconfont undefined"></i>
  Python
</a></li><li class="dropdown-item"><!----> <a href="/categories/Nvidia/" class="nav-link"><i class="iconfont undefined"></i>
  Nvidia
</a></li><li class="dropdown-item"><!----> <a href="/categories/Shell/" class="nav-link"><i class="iconfont undefined"></i>
  Shell
</a></li><li class="dropdown-item"><!----> <a href="/categories/Tex/" class="nav-link"><i class="iconfont undefined"></i>
  Tex
</a></li><li class="dropdown-item"><!----> <a href="/categories/Rust/" class="nav-link"><i class="iconfont undefined"></i>
  Rust
</a></li><li class="dropdown-item"><!----> <a href="/categories/Vue/" class="nav-link"><i class="iconfont undefined"></i>
  Vue
</a></li><li class="dropdown-item"><!----> <a href="/categories/视频编解码/" class="nav-link"><i class="iconfont undefined"></i>
  视频编解码
</a></li><li class="dropdown-item"><!----> <a href="/categories/计算机网络/" class="nav-link"><i class="iconfont undefined"></i>
  计算机网络
</a></li><li class="dropdown-item"><!----> <a href="/categories/SDN/" class="nav-link"><i class="iconfont undefined"></i>
  SDN
</a></li><li class="dropdown-item"><!----> <a href="/categories/论文笔记/" class="nav-link"><i class="iconfont undefined"></i>
  论文笔记
</a></li><li class="dropdown-item"><!----> <a href="/categories/讨论/" class="nav-link"><i class="iconfont undefined"></i>
  讨论
</a></li><li class="dropdown-item"><!----> <a href="/categories/边缘计算/" class="nav-link"><i class="iconfont undefined"></i>
  边缘计算
</a></li><li class="dropdown-item"><!----> <a href="/categories/量子信息技术/" class="nav-link"><i class="iconfont undefined"></i>
  量子信息技术
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><a href="http://profile.yindaheng98.top" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-account"></i>
  About
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <a href="https://github.com/yindaheng98/Notebook/tree/master/学习笔记" target="_blank" rel="noopener noreferrer" class="repo-link"><i class="iconfont reco-查看源码"></i>
    查看源码
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>【纯转载】图解Swin Transformer</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#引言" class="sidebar-link">引言</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#整体架构" class="sidebar-link">整体架构</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#patch-embedding" class="sidebar-link">Patch Embedding</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#patch-merging" class="sidebar-link">Patch Merging</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#window-partition-reverse" class="sidebar-link">Window Partition/Reverse</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#window-attention" class="sidebar-link">Window Attention</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#shifted-window-attention" class="sidebar-link">Shifted Window Attention</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#特征图移位操作" class="sidebar-link">特征图移位操作</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#attention-mask" class="sidebar-link">Attention Mask</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#transformer-block整体架构" class="sidebar-link">Transformer Block整体架构</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#实验结果" class="sidebar-link">实验结果</a><ul class="sidebar-sub-headers"></ul></li><li><a href="/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%9B%BE%E8%A7%A3SwinTransformer.html#总结" class="sidebar-link">总结</a><ul class="sidebar-sub-headers"></ul></li></ul></section></li></ul> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-95c9a4e8 data-v-42dd5e05><h3 class="title" style="display:none;" data-v-95c9a4e8 data-v-95c9a4e8>【纯转载】图解Swin Transformer</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-95c9a4e8 data-v-95c9a4e8><input type="password" value="" data-v-95c9a4e8> <span data-v-95c9a4e8>Konck! Knock!</span> <button data-v-95c9a4e8>OK</button></label> <div class="footer" style="display:none;" data-v-95c9a4e8 data-v-95c9a4e8><span data-v-95c9a4e8><i class="iconfont reco-theme" data-v-95c9a4e8></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-95c9a4e8>vuePress-theme-reco</a></span> <span data-v-95c9a4e8><i class="iconfont reco-copyright" data-v-95c9a4e8></i> <a data-v-95c9a4e8><span data-v-95c9a4e8>Howard Yin</span>
            
          <span data-v-95c9a4e8>2021 - </span>
          2025
        </a></span></div></div> <div data-v-42dd5e05><main class="page"><div class="page-title" style="display:none;"><h1>【纯转载】图解Swin Transformer</h1> <hr> <div data-v-3d9cec6e><i class="iconfont reco-account" data-v-3d9cec6e><span data-v-3d9cec6e>Howard Yin</span></i> <i class="iconfont reco-date" data-v-3d9cec6e><span data-v-3d9cec6e>2022-07-16 11:50:05</span></i> <!----> <i class="iconfont reco-tag tags" data-v-3d9cec6e><span class="tag-item" data-v-3d9cec6e>人工智能</span><span class="tag-item" data-v-3d9cec6e>Transformer</span><span class="tag-item" data-v-3d9cec6e>SwinTransformer</span><span class="tag-item" data-v-3d9cec6e>神经网络</span><span class="tag-item" data-v-3d9cec6e>注意力机制</span></i></div></div> <div class="theme-reco-content content__default" style="display:none;"><p><a href="https://zhuanlan.zhihu.com/p/367111046" target="_blank" rel="noopener noreferrer">原文<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="引言"><a href="#引言" class="header-anchor">#</a> <strong>引言</strong></h2> <p>目前Transformer应用到图像领域主要有两大挑战：</p> <ol><li>视觉实体变化大，在不同场景下视觉Transformer性能未必很好</li> <li>图像分辨率高，像素点多，Transformer基于全局自注意力的计算导致计算量较大</li></ol> <p>针对上述两个问题，我们提出了一种 <strong>包含滑窗操作，具有层级设计</strong> 的Swin Transformer。</p> <p>其中滑窗操作包括 <strong>不重叠的local window，和重叠的cross-window</strong> 。将注意力计算限制在一个窗口中， <strong>一方面能引入CNN卷积操作的局部性，另一方面能节省计算量</strong> 。</p> <p><img src="zhimg/v2-74c856e61d60781c89c3813367289462_r.jpg" alt=""></p> <p>在各大图像任务上，Swin Transformer都具有很好的性能。</p> <p>本文比较长，会根据官方的<a href="https://link.zhihu.com/?target=https%3A//github.com/microsoft/Swin-Transformer" target="_blank" rel="noopener noreferrer">开源代码<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>进行讲解，有兴趣的可以去阅读下<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2103.14030.pdf" target="_blank" rel="noopener noreferrer">论文原文<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>。</p> <h2 id="整体架构"><a href="#整体架构" class="header-anchor">#</a> <strong>整体架构</strong></h2> <p>我们先看下Swin Transformer的整体架构</p> <p><img src="zhimg/v2-9a475a9b8389c48ea61da8f0b821fe56_r.jpg" alt=""></p> <p>整个模型采取层次化的设计，一共包含4个Stage，每个stage都会缩小输入特征图的分辨率，像CNN一样逐层扩大感受野。</p> <ol><li>在输入开始的时候，做了一个<code>Patch Embedding</code>，将图片切成一个个图块，并嵌入到<code>Embedding</code>。</li> <li>在每个Stage里，由<code>Patch Merging</code>和多个Block组成。</li> <li>其中<code>Patch Merging</code>模块主要在每个Stage一开始降低图片分辨率。</li> <li>而Block具体结构如右图所示，主要是<code>LayerNorm</code>，<code>MLP</code>，<code>Window Attention</code> 和 <code>Shifted Window Attention</code>组成 (为了方便讲解，我会省略掉一些参数)</li></ol> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">SwinTransformer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token comment"># absolute position embedding</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>ape<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>absolute_pos_embed <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_patches<span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
        self<span class="token punctuation">.</span>pos_drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span>drop_rate<span class="token punctuation">)</span>

        <span class="token comment"># build layers</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i_layer <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            layer <span class="token operator">=</span> BasicLayer<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>layer<span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>norm <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_features<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>avgpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool1d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>head <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_features<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span> <span class="token keyword">if</span> num_classes <span class="token operator">&amp;</span>gt<span class="token punctuation">;</span> <span class="token number">0</span> <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward_features</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>patch_embed<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>ape<span class="token punctuation">:</span>
            x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>absolute_pos_embed
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            x <span class="token operator">=</span> layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment"># B L C</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>avgpool<span class="token punctuation">(</span>x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># B C 1</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>forward_features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>head<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br></div></div><p>其中有几个地方处理方法与ViT不同：</p> <ol><li>ViT在输入会给embedding进行位置编码。而Swin-T这里则是作为一个 <strong>可选项</strong> （<code>self.ape</code>），Swin-T是在计算Attention的时候做了一个<code>相对位置编码</code></li> <li>ViT会单独加上一个可学习参数，作为分类的token。而Swin-T则是 <strong>直接做平均</strong> ，输出分类，有点类似CNN最后的全局平均池化层</li></ol> <p>接下来我们看下各个组件的构成</p> <h2 id="patch-embedding"><a href="#patch-embedding" class="header-anchor">#</a> <strong>Patch Embedding</strong></h2> <p>在输入进Block前，我们需要将图片切成一个个patch，然后嵌入向量。</p> <p>具体做法是对原始图片裁成一个个 <code>patch_size * patch_size</code>的窗口大小，然后进行嵌入。</p> <p>这里可以通过二维卷积层， <strong>将stride，kernelsize设置为patch_size大小</strong> 。设定输出通道来确定嵌入向量的大小。最后将H,W维度展开，并移动到第一维度</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn

<span class="token keyword">class</span> <span class="token class-name">PatchEmbed</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img_size<span class="token operator">=</span><span class="token number">224</span><span class="token punctuation">,</span> patch_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> in_chans<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> embed_dim<span class="token operator">=</span><span class="token number">96</span><span class="token punctuation">,</span> norm_layer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        img_size <span class="token operator">=</span> to_2tuple<span class="token punctuation">(</span>img_size<span class="token punctuation">)</span> <span class="token comment"># -&amp;gt; (img_size, img_size)</span>
        patch_size <span class="token operator">=</span> to_2tuple<span class="token punctuation">(</span>patch_size<span class="token punctuation">)</span> <span class="token comment"># -&amp;gt; (patch_size, patch_size)</span>
        patches_resolution <span class="token operator">=</span> <span class="token punctuation">[</span>img_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">//</span> patch_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> img_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> patch_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>img_size <span class="token operator">=</span> img_size
        self<span class="token punctuation">.</span>patch_size <span class="token operator">=</span> patch_size
        self<span class="token punctuation">.</span>patches_resolution <span class="token operator">=</span> patches_resolution
        self<span class="token punctuation">.</span>num_patches <span class="token operator">=</span> patches_resolution<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> patches_resolution<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

        self<span class="token punctuation">.</span>in_chans <span class="token operator">=</span> in_chans
        self<span class="token punctuation">.</span>embed_dim <span class="token operator">=</span> embed_dim

        self<span class="token punctuation">.</span>proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_chans<span class="token punctuation">,</span> embed_dim<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span>patch_size<span class="token punctuation">,</span> stride<span class="token operator">=</span>patch_size<span class="token punctuation">)</span>
        <span class="token keyword">if</span> norm_layer <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>norm <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span>embed_dim<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>norm <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 假设采取默认参数</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 出来的是(N, 96, 224/4, 224/4) </span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># 把HW维展开，(N, 96, 56*56)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># 把通道维放到最后 (N, 56*56, 96)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>norm <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br></div></div><h2 id="patch-merging"><a href="#patch-merging" class="header-anchor">#</a> <strong>Patch Merging</strong></h2> <p>该模块的作用是在每个Stage开始前做降采样，用于缩小分辨率，调整通道数 进而形成层次化的设计，同时也能节省一定运算量。</p> <blockquote><p>在CNN中，则是在每个Stage开始前用<code>stride=2</code>的卷积/池化层来降低分辨率。</p></blockquote> <p>每次降采样是两倍，因此 <strong>在行方向和列方向上，间隔2选取元素</strong> 。</p> <p>然后拼接在一起作为一整个张量，最后展开。 <strong>此时通道维度会变成原先的4倍</strong> （因为H,W各缩小2倍），此时再通过一个 <strong>全连接层再调整通道维度为原来的两倍</strong></p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">PatchMerging</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_resolution<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> norm_layer<span class="token operator">=</span>nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>input_resolution <span class="token operator">=</span> input_resolution
        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> dim
        self<span class="token punctuation">.</span>reduction <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">*</span> dim<span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">*</span> dim<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>norm <span class="token operator">=</span> norm_layer<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">*</span> dim<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        x: B, H*W, C
        &quot;&quot;&quot;</span>
        H<span class="token punctuation">,</span> W <span class="token operator">=</span> self<span class="token punctuation">.</span>input_resolution
        B<span class="token punctuation">,</span> L<span class="token punctuation">,</span> C <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        <span class="token keyword">assert</span> L <span class="token operator">==</span> H <span class="token operator">*</span> W<span class="token punctuation">,</span> <span class="token string">&quot;input feature has wrong size&quot;</span>
        <span class="token keyword">assert</span> H <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token keyword">and</span> W <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string-interpolation"><span class="token string">f&quot;x size (</span><span class="token interpolation"><span class="token punctuation">{</span>H<span class="token punctuation">}</span></span><span class="token string">*</span><span class="token interpolation"><span class="token punctuation">{</span>W<span class="token punctuation">}</span></span><span class="token string">) are not even.&quot;</span></span>

        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> C<span class="token punctuation">)</span>

        x0 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># B H/2 W/2 C</span>
        x1 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># B H/2 W/2 C</span>
        x2 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># B H/2 W/2 C</span>
        x3 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># B H/2 W/2 C</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x0<span class="token punctuation">,</span> x1<span class="token punctuation">,</span> x2<span class="token punctuation">,</span> x3<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># B H/2 W/2 4*C</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span> <span class="token operator">*</span> C<span class="token punctuation">)</span>  <span class="token comment"># B H/2*W/2 4*C</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>reduction<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">return</span> x
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><p>下面是一个示意图（输入张量N=1, H=W=8, C=1，不包含最后的全连接层调整）</p> <p><img src="zhimg/v2-a1a0ea5d9455083caed65006433c4efe_r.jpg" alt=""></p> <blockquote><p>个人感觉这像是PixelShuffle的反操作</p></blockquote> <h2 id="window-partition-reverse"><a href="#window-partition-reverse" class="header-anchor">#</a> <strong>Window Partition/Reverse</strong></h2> <p><code>window partition</code>函数是用于对张量划分窗口，指定窗口大小。将原本的张量从 <code>N H W C</code>, 划分成 <code>num_windows*B, window_size, window_size, C</code>，其中  <strong>num_windows = H<em>W / (window_size</em>window_size)</strong> ，即窗口的个数。而<code>window reverse</code>函数则是对应的逆过程。这两个函数会在后面的<code>Window Attention</code>用到。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">window_partition</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> window_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> C <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H <span class="token operator">//</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> W <span class="token operator">//</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> C<span class="token punctuation">)</span>
    windows <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> C<span class="token punctuation">)</span>
    <span class="token keyword">return</span> windows

<span class="token keyword">def</span> <span class="token function">window_reverse</span><span class="token punctuation">(</span>windows<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span><span class="token punctuation">:</span>
    B <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>windows<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token punctuation">(</span>H <span class="token operator">*</span> W <span class="token operator">/</span> window_size <span class="token operator">/</span> window_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> windows<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H <span class="token operator">//</span> window_size<span class="token punctuation">,</span> W <span class="token operator">//</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> x
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><h2 id="window-attention"><a href="#window-attention" class="header-anchor">#</a> <strong>Window Attention</strong></h2> <p>这是这篇文章的关键。传统的Transformer都是 <strong>基于全局来计算注意力的</strong> ，因此计算复杂度十分高。而Swin Transformer则将 <strong>注意力的计算限制在每个窗口内</strong> ，进而减少了计算量。</p> <p>我们先简单看下公式</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy="false">(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><mi>S</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><mi>d</mi></msqrt></mfrac><mo>+</mo><mi>B</mi><mo stretchy="false">)</mo><mi>V</mi><mspace linebreak="newline"></mspace></mrow><annotation encoding="application/x-tex">Attention(Q, K, V) = Softmax(\frac{QK^T}{\sqrt{d}}+B)V \\
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">A</span><span class="mord mathdefault">t</span><span class="mord mathdefault">t</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord mathdefault">t</span><span class="mord mathdefault">i</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mopen">(</span><span class="mord mathdefault">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.448331em;vertical-align:-0.93em;"></span><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class="mord mathdefault">t</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183309999999999em;"><span style="top:-2.17778em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.93222em;"><span class="svg-align" style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord" style="padding-left:0.833em;"><span class="mord mathdefault">d</span></span></span><span style="top:-2.89222em;"><span class="pstrut" style="height:3em;"></span><span class="hide-tail" style="min-width:0.853em;height:1.08em;"><svg width="400em" height="1.08em" viewBox="0 0 400000 1080" preserveAspectRatio="xMinYMin slice"><path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.10777999999999999em;"><span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault">Q</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">K</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413309999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.93em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="mclose">)</span><span class="mord mathdefault" style="margin-right:0.22222em;">V</span></span><span class="mspace newline"></span></span></span></span></p> <p>主要区别是在原始计算Attention的公式中的Q,K时 <strong>加入了相对位置编码</strong> 。后续实验有证明相对位置编码的加入提升了模型性能。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">WindowAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">r&quot;&quot;&quot; Window based multi-head self attention (W-MSA) module with relative position bias.
    It supports both of shifted and non-shifted window.

    Args:
        dim (int): Number of input channels.
        window_size (tuple[int]): The height and width of the window.
        num_heads (int): Number of attention heads.
        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True
        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set
        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0
        proj_drop (float, optional): Dropout ratio of output. Default: 0.0
    &quot;&quot;&quot;</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> window_size<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> qkv_bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> qk_scale<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> attn_drop<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> proj_drop<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dim <span class="token operator">=</span> dim
        self<span class="token punctuation">.</span>window_size <span class="token operator">=</span> window_size  <span class="token comment"># Wh, Ww</span>
        self<span class="token punctuation">.</span>num_heads <span class="token operator">=</span> num_heads <span class="token comment"># nH</span>
        head_dim <span class="token operator">=</span> dim <span class="token operator">//</span> num_heads <span class="token comment"># 每个注意力头对应的通道数</span>
        self<span class="token punctuation">.</span>scale <span class="token operator">=</span> qk_scale <span class="token keyword">or</span> head_dim <span class="token operator">**</span> <span class="token operator">-</span><span class="token number">0.5</span>

        <span class="token comment"># define a parameter table of relative position bias</span>
        self<span class="token punctuation">.</span>relative_position_bias_table <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>
            torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> window_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> window_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 设置一个形状为（2*(Wh-1) * 2*(Ww-1), nH）的可学习变量，用于后续的位置编码</span>
  
        self<span class="token punctuation">.</span>qkv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim <span class="token operator">*</span> <span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span>qkv_bias<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>attn_drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>attn_drop<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>dim<span class="token punctuation">,</span> dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>proj_drop <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>proj_drop<span class="token punctuation">)</span>

        trunc_normal_<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relative_position_bias_table<span class="token punctuation">,</span> std<span class="token operator">=</span><span class="token number">.02</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>softmax <span class="token operator">=</span> nn<span class="token punctuation">.</span>Softmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
     <span class="token comment"># 相关位置编码...</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br></div></div><p>下面我把涉及到相关位置编码的逻辑给单独拿出来，这部分比较绕</p> <p>首先QK计算出来的Attention张量形状为<code>(numWindows*B, num_heads, window_size*window_size, window_size*window_size)</code>。</p> <p>而对于Attention张量来说， <strong>以不同元素为原点，其他元素的坐标也是不同的</strong> ，以<code>window_size=2</code>为例，其相对位置编码如下图所示</p> <p><img src="zhimg/v2-c7140d26adf8a4c9d8b2609488ce71ee_1440w.jpg" alt=""></p> <p>首先我们利用<code>torch.arange</code>和<code>torch.meshgrid</code>函数生成对应的坐标，这里我们以<code>windowsize=2</code>为例子</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>coords_h <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
coords_w <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
coords <span class="token operator">=</span> torch<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span><span class="token punctuation">[</span>coords_h<span class="token punctuation">,</span> coords_w<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># -&amp;gt; 2*(wh, ww)</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
  (tensor([[0, 0, 0],
           [1, 1, 1],
           [2, 2, 2]]), 
   tensor([[0, 1, 2],
           [0, 1, 2],
           [0, 1, 2]]))
&quot;&quot;&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br></div></div><p>然后堆叠起来，展开为一个二维向量</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>coords <span class="token operator">=</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>coords<span class="token punctuation">)</span>  <span class="token comment"># 2, Wh, Ww</span>
coords_flatten <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>coords<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 2, Wh*Ww</span>
<span class="token triple-quoted-string string">&quot;&quot;&quot;
tensor([[0, 0, 1, 1, 2, 2],
        [0, 1, 2, 0, 1, 2]])
&quot;&quot;&quot;</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br></div></div><p>利用广播机制，分别在第一维，第二维，插入一个维度，进行广播相减，得到 <code>2, wh*ww, wh*ww</code>的张量</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>relative_coords_first <span class="token operator">=</span> coords_flatten<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span>  <span class="token comment"># 2, wh*ww, 1</span>
relative_coords_second <span class="token operator">=</span> coords_flatten<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># 2, 1, wh*ww</span>
relative_coords <span class="token operator">=</span> relative_coords_first <span class="token operator">-</span> relative_coords_second <span class="token comment"># 最终得到 2, wh*ww, wh*ww 形状的张量</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>因为采取的是相减，所以得到的索引是从负数开始的， <strong>我们加上偏移量，让其从0开始</strong> 。</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>relative_coords <span class="token operator">=</span> relative_coords<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># Wh*Ww, Wh*Ww, 2</span>
relative_coords<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span>
relative_coords<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div><p>后续我们需要将其展开成一维偏移量。而对于(1，2）和（2，1）这两个坐标。在二维上是不同的， <strong>但是通过将x,y坐标相加转换为一维偏移的时候，他的偏移量是相等的</strong> 。</p> <p><img src="zhimg/v2-5b1f589ca71a4bc406a266296025b4b4_r.jpg" alt=""></p> <p>所以最后我们对其中做了个乘法操作，以进行区分</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>relative_coords<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*=</span> <span class="token number">2</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> <span class="token number">1</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br></div></div><p><img src="zhimg/v2-0c99206fb39da67bae3415a650c38742_r.jpg" alt=""></p> <p>然后再最后一维上进行求和，展开成一个一维坐标，并注册为一个不参与网络学习的变量</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>relative_position_index <span class="token operator">=</span> relative_coords<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># Wh*Ww, Wh*Ww</span>
self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">&quot;relative_position_index&quot;</span><span class="token punctuation">,</span> relative_position_index<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>接着我们看前向代码</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot;
        Args:
            x: input features with shape of (num_windows*B, N, C)
            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None
        &quot;&quot;&quot;</span>
        B_<span class="token punctuation">,</span> N<span class="token punctuation">,</span> C <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        
        qkv <span class="token operator">=</span> self<span class="token punctuation">.</span>qkv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>B_<span class="token punctuation">,</span> N<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> C <span class="token operator">//</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
        q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> v <span class="token operator">=</span> qkv<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> qkv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> qkv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>  <span class="token comment"># make torchscript happy (cannot use tensor as tuple)</span>

        q <span class="token operator">=</span> q <span class="token operator">*</span> self<span class="token punctuation">.</span>scale
        attn <span class="token operator">=</span> <span class="token punctuation">(</span>q @ k<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        relative_position_bias <span class="token operator">=</span> self<span class="token punctuation">.</span>relative_position_bias_table<span class="token punctuation">[</span>self<span class="token punctuation">.</span>relative_position_index<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>window_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># Wh*Ww,Wh*Ww,nH</span>
        relative_position_bias <span class="token operator">=</span> relative_position_bias<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># nH, Wh*Ww, Wh*Ww</span>
        attn <span class="token operator">=</span> attn <span class="token operator">+</span> relative_position_bias<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># (1, num_heads, windowsize, windowsize)</span>

        <span class="token keyword">if</span> mask <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span> <span class="token comment"># 下文会分析到</span>
            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            attn <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>attn<span class="token punctuation">)</span>

        attn <span class="token operator">=</span> self<span class="token punctuation">.</span>attn_drop<span class="token punctuation">(</span>attn<span class="token punctuation">)</span>

        x <span class="token operator">=</span> <span class="token punctuation">(</span>attn @ v<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>B_<span class="token punctuation">,</span> N<span class="token punctuation">,</span> C<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>proj_drop<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><ol><li>首先输入张量形状为 <code>numWindows*B, window_size * window_size, C</code>（后续会解释）</li> <li>然后经过<code>self.qkv</code>这个全连接层后，进行reshape，调整轴的顺序，得到形状为<code>3, numWindows*B, num_heads, window_size*window_size, c//num_heads</code>，并分配给<code>q,k,v</code>。</li> <li>根据公式，我们对<code>q</code>乘以一个<code>scale</code>缩放系数，然后与<code>k</code>（为了满足矩阵乘要求，需要将最后两个维度调换）进行相乘。得到形状为<code>(numWindows*B, num_heads, window_size*window_size, window_size*window_size)</code>的<code>attn</code>张量</li> <li>之前我们针对位置编码设置了个形状为<code>(2*window_size-1*2*window_size-1, numHeads)</code>的可学习变量。我们用计算得到的相对编码位置索引<code>self.relative_position_index</code>选取，得到形状为<code>(window_size*window_size, window_size*window_size, numHeads)</code>的编码，加到<code>attn</code>张量上</li> <li>暂不考虑mask的情况，剩下就是跟transformer一样的softmax，dropout，与<code>V</code>矩阵乘，再经过一层全连接层和dropout</li></ol> <h2 id="shifted-window-attention"><a href="#shifted-window-attention" class="header-anchor">#</a> <strong>Shifted Window Attention</strong></h2> <p>前面的Window Attention是在每个窗口下计算注意力的，为了更好的和其他window进行信息交互，Swin Transformer还引入了shifted window操作。</p> <p><img src="zhimg/v2-07a98325a29db1da6521e4ddaaed3c88_r.jpg" alt=""></p> <p>左边是没有重叠的Window Attention，而右边则是将窗口进行移位的Shift Window Attention。可以看到移位后的窗口包含了原本相邻窗口的元素。但这也引入了一个新问题，即 <strong>window的个数翻倍了</strong> ，由原本四个窗口变成了9个窗口。</p> <p>在实际代码里，我们是 <strong>通过对特征图移位，并给Attention设置mask来间接实现的</strong> 。能在 <strong>保持原有的window个数下</strong> ，最后的计算结果等价。</p> <p><img src="zhimg/v2-84b7dd5ba83bf0c686a133dec758d974_r.jpg" alt=""></p> <h2 id="特征图移位操作"><a href="#特征图移位操作" class="header-anchor">#</a> <strong>特征图移位操作</strong></h2> <p>代码里对特征图移位是通过<code>torch.roll</code>来实现的，下面是示意图</p> <p><img src="zhimg/v2-8d8274d62026e0732c8a7827de1070fc_r.jpg" alt=""></p> <blockquote><p>如果需要<code>reverse cyclic shift</code>的话只需把参数<code>shifts</code>设置为对应的正数值。</p></blockquote> <h2 id="attention-mask"><a href="#attention-mask" class="header-anchor">#</a> <strong>Attention Mask</strong></h2> <p>我认为这是Swin Transformer的精华，通过设置合理的mask，让<code>Shifted Window Attention</code>在与<code>Window Attention</code>相同的窗口个数下，达到等价的计算结果。</p> <p>首先我们对Shift Window后的每个窗口都给上index，并且做一个<code>roll</code>操作（window_size=2, shift_size=-1）</p> <p><img src="zhimg/v2-52b0bec2b0e2341e1eab1fd6342bc9e6_r.jpg" alt=""></p> <p>我们希望在计算Attention的时候， <strong>让具有相同index QK进行计算，而忽略不同index QK计算结果</strong> 。</p> <p>最后正确的结果如下图所示</p> <p><img src="zhimg/v2-af19485ae400a2f52ede6306fcfb078e_r.jpg" alt=""></p> <p>而要想在原始四个窗口下得到正确的结果，我们就必须给Attention的结果加入一个mask（如上图最右边所示）</p> <p>相关代码如下：</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>shift_size <span class="token operator">&amp;</span>gt<span class="token punctuation">;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token comment"># calculate attention mask for SW-MSA</span>
            H<span class="token punctuation">,</span> W <span class="token operator">=</span> self<span class="token punctuation">.</span>input_resolution
            img_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 1 H W 1</span>
            h_slices <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            w_slices <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                        <span class="token builtin">slice</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            cnt <span class="token operator">=</span> <span class="token number">0</span>
            <span class="token keyword">for</span> h <span class="token keyword">in</span> h_slices<span class="token punctuation">:</span>
                <span class="token keyword">for</span> w <span class="token keyword">in</span> w_slices<span class="token punctuation">:</span>
                    img_mask<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> h<span class="token punctuation">,</span> w<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> cnt
                    cnt <span class="token operator">+=</span> <span class="token number">1</span>

            mask_windows <span class="token operator">=</span> window_partition<span class="token punctuation">(</span>img_mask<span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span>  <span class="token comment"># nW, window_size, window_size, 1</span>
            mask_windows <span class="token operator">=</span> mask_windows<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size <span class="token operator">*</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span>
            attn_mask <span class="token operator">=</span> mask_windows<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">-</span> mask_windows<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
            attn_mask <span class="token operator">=</span> attn_mask<span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>attn_mask <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">100.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>masked_fill<span class="token punctuation">(</span>attn_mask <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br></div></div><p>以上图的设置，我们用这段代码会得到这样的一个mask</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>

         <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span>   <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
           <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">,</span>    <span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br></div></div><p>在之前的window attention模块的前向代码里，包含这么一段</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>        <span class="token keyword">if</span> mask <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            nW <span class="token operator">=</span> mask<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            attn <span class="token operator">=</span> attn<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B_ <span class="token operator">//</span> nW<span class="token punctuation">,</span> nW<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> N<span class="token punctuation">,</span> N<span class="token punctuation">)</span> <span class="token operator">+</span> mask<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
            attn <span class="token operator">=</span> attn<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_heads<span class="token punctuation">,</span> N<span class="token punctuation">,</span> N<span class="token punctuation">)</span>
            attn <span class="token operator">=</span> self<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>attn<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><p>将mask加到attention的计算结果，并进行softmax。mask的值设置为-100，softmax后就会忽略掉对应的值</p> <h2 id="transformer-block整体架构"><a href="#transformer-block整体架构" class="header-anchor">#</a> <strong>Transformer Block整体架构</strong></h2> <p><img src="zhimg/v2-b1f64ea254af2c7b1cdbaf9288731371_r.jpg" alt=""></p> <p>两个连续的Block架构如上图所示，需要注意的是一个Stage包含的Block个数必须是偶数，因为需要交替包含一个含有<code>Window Attention</code>的Layer和含有<code>Shifted Window Attention</code>的Layer。</p> <p>我们看下Block的前向代码</p> <div class="language-python line-numbers-mode"><pre class="language-python"><code>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        H<span class="token punctuation">,</span> W <span class="token operator">=</span> self<span class="token punctuation">.</span>input_resolution
        B<span class="token punctuation">,</span> L<span class="token punctuation">,</span> C <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        <span class="token keyword">assert</span> L <span class="token operator">==</span> H <span class="token operator">*</span> W<span class="token punctuation">,</span> <span class="token string">&quot;input feature has wrong size&quot;</span>

        shortcut <span class="token operator">=</span> x
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">,</span> C<span class="token punctuation">)</span>

        <span class="token comment"># cyclic shift</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>shift_size <span class="token operator">&amp;</span>gt<span class="token punctuation">;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            shifted_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>roll<span class="token punctuation">(</span>x<span class="token punctuation">,</span> shifts<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">,</span> <span class="token operator">-</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">)</span><span class="token punctuation">,</span> dims<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            shifted_x <span class="token operator">=</span> x

        <span class="token comment"># partition windows</span>
        x_windows <span class="token operator">=</span> window_partition<span class="token punctuation">(</span>shifted_x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">)</span>  <span class="token comment"># nW*B, window_size, window_size, C</span>
        x_windows <span class="token operator">=</span> x_windows<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size <span class="token operator">*</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> C<span class="token punctuation">)</span>  <span class="token comment"># nW*B, window_size*window_size, C</span>

        <span class="token comment"># W-MSA/SW-MSA</span>
        attn_windows <span class="token operator">=</span> self<span class="token punctuation">.</span>attn<span class="token punctuation">(</span>x_windows<span class="token punctuation">,</span> mask<span class="token operator">=</span>self<span class="token punctuation">.</span>attn_mask<span class="token punctuation">)</span>  <span class="token comment"># nW*B, window_size*window_size, C</span>

        <span class="token comment"># merge windows</span>
        attn_windows <span class="token operator">=</span> attn_windows<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> C<span class="token punctuation">)</span>
        shifted_x <span class="token operator">=</span> window_reverse<span class="token punctuation">(</span>attn_windows<span class="token punctuation">,</span> self<span class="token punctuation">.</span>window_size<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>  <span class="token comment"># B H' W' C</span>

        <span class="token comment"># reverse cyclic shift</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>shift_size <span class="token operator">&amp;</span>gt<span class="token punctuation">;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> torch<span class="token punctuation">.</span>roll<span class="token punctuation">(</span>shifted_x<span class="token punctuation">,</span> shifts<span class="token operator">=</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>shift_size<span class="token punctuation">,</span> self<span class="token punctuation">.</span>shift_size<span class="token punctuation">)</span><span class="token punctuation">,</span> dims<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> shifted_x
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>B<span class="token punctuation">,</span> H <span class="token operator">*</span> W<span class="token punctuation">,</span> C<span class="token punctuation">)</span>

        <span class="token comment"># FFN</span>
        x <span class="token operator">=</span> shortcut <span class="token operator">+</span> self<span class="token punctuation">.</span>drop_path<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>drop_path<span class="token punctuation">(</span>self<span class="token punctuation">.</span>mlp<span class="token punctuation">(</span>self<span class="token punctuation">.</span>norm2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> x
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br></div></div><p>整体流程如下</p> <ol><li>先对特征图进行LayerNorm</li> <li>通过<code>self.shift_size</code>决定是否需要对特征图进行shift</li> <li>然后将特征图切成一个个窗口</li> <li>计算Attention，通过<code>self.attn_mask</code>来区分<code>Window Attention</code>还是<code>Shift Window Attention</code></li> <li>将各个窗口合并回来</li> <li>如果之前有做shift操作，此时进行<code>reverse shift</code>，把之前的shift操作恢复</li> <li>做dropout和残差连接</li> <li>再通过一层LayerNorm+全连接层，以及dropout和残差连接</li></ol> <h2 id="实验结果"><a href="#实验结果" class="header-anchor">#</a> <strong>实验结果</strong></h2> <p><img src="zhimg/v2-bf00e048de979decd68ebc7c5372cb27_r.jpg" alt=""></p> <p>在ImageNet22K数据集上，准确率能达到惊人的86.4%。另外在检测，分割等任务上表现也很优异，感兴趣的可以翻看论文最后的实验部分。</p> <h2 id="总结"><a href="#总结" class="header-anchor">#</a> <strong>总结</strong></h2> <p>这篇文章创新点很棒，引入window这一个概念，将CNN的局部性引入，还能控制模型整体计算量。在Shift Window Attention部分，用一个mask和移位操作，很巧妙的实现计算等价。作者的代码也写得十分赏心悦目，推荐阅读！</p></div> <footer class="page-edit" style="display:none;"><div class="edit-link"><a href="https://github.com/yindaheng98/Notebook/edit/master/学习笔记/人工智能/图解SwinTransformer.md" target="_blank" rel="noopener noreferrer">帮助我们改善此页面！</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <div class="last-updated"><span class="prefix">创建于: </span> <span class="time">2022-06-12 08:02:17</span></div> <br> <div class="last-updated"><span class="prefix">更新于: </span> <span class="time">2022-07-16 11:50:59</span></div></footer> <!----> <!----></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-44bd5a18 data-v-44bd5a18><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-44bd5a18><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-44bd5a18></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-44bd5a18></path></svg></div></div></div>
    <script src="/assets/js/app.1c89d7eb.js" defer></script><script src="/assets/js/3.63b8c0eb.js" defer></script><script src="/assets/js/1.be3d2055.js" defer></script><script src="/assets/js/154.60508725.js" defer></script>
  </body>
</html>
